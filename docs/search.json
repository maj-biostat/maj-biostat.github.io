[
  {
    "objectID": "notebooks/custom-distribution-stan.html",
    "href": "notebooks/custom-distribution-stan.html",
    "title": "User-defined Probability Distributions in Stan",
    "section": "",
    "text": "Overview\nSome of this material can be found in the stan user guide and this is solely to serve as a reference in my own words.\nTo implement, you just need to provide a function to increment the total log-probability appropriately.\n\n\n\n\n\n\nNote\n\n\n\nWhen a function with the name ending in *_lpdf* or *_lpmf* is defined, the stan compiler automatically makes a *_lupdf* or lupmf version. Only normalised custom distributions are permitted.\n\n\nAssume that we want to create a custom distribution per:\n\\[\n\\begin{aligned}\nf(x) &= (1-a) x^{-a}\n\\end{aligned}\n\\]\ndefined for \\(a \\in [0,1]\\) and \\(x \\in [0,1]\\) with cdf:\n\\[\n\\begin{aligned}\nF_x &= x^{a-1}\n\\end{aligned}\n\\]\nWe can generate draws from this distribution using the inverse cdf method:\n\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.8.1\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /Users/mark/.cmdstan/cmdstan-2.35.0\n\n\n- CmdStan version: 2.35.0\n\nf_x &lt;- function(x, a){\n  if(a &lt; 0 | a &gt; 1) stop(\"only defined for a in [0,1]\")\n  if(any(x &lt; 0 | x &gt; 1)) stop(\"only defined for x in [0,1]\")\n  (1-a) * x ^ -a\n}\nF_x &lt;- function(x, a){\n  if(a &lt; 0 | a &gt; 1) stop(\"only defined for a in [0,1]\")\n  if(any(x &lt; 0 | x &gt; 1)) stop(\"only defined for x in [0,1]\")\n  x^(1-a)\n}\nF_inv_x &lt;- function(u, a){\n  if(a &lt; 0 | a &gt; 1) stop(\"only defined for a in [0,1]\")\n  if(any(u &lt; 0 | u &gt; 1)) stop(\"only defined for x in [0,1]\")\n  u ^ (1 / (1-a))\n}\n\na &lt;- 0.35\nx &lt;- seq(0, 1, len = 1000)\nd_fig &lt;- data.table(x = x, y = f_x(x, a))\nd_sim &lt;- data.table(\n  y_sim = F_inv_x(runif(1e6), a)\n)\n\nggplot(d_fig, aes(x = x, y = y)) +\n  geom_histogram(data = d_sim, aes(x = y_sim, y = ..density..),\n               inherit.aes = F, fill = 1, alpha = 0.2,\n               binwidth = density(d_sim$y_sim)$bw) + \n  geom_line() +\n  theme_bw()\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\n\n\n\nfunctions {\n  real custom_lpdf(vector x, real alpha) {\n    \n    int n_x = num_elements(x);\n    vector[n_x] lpdf;\n    for(i in 1:n_x){\n      \n      lpdf[i] = log1m(alpha) - alpha * log(x[i]);\n    }  \n    return sum(lpdf);\n  }\n}\ndata {\n  int N;\n  vector[N] y;\n}\n\nparameters {\n  real&lt;lower=0, upper = 1&gt; a;\n}\nmodel {\n  target += exponential_lpdf(a | 1);\n  target += custom_lpdf(y | a);   \n}\n\n\n\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/custom-dist-1.stan\")\n\nld = list(\n  N = 1000, \n  y = d_sim$y_sim[1:1000]\n)\n\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n  parallel_chains = 1, chains = 1, refresh = 0, show_exceptions = F,\n  max_treedepth = 10)\n\nRunning MCMC with 1 chain...\n\nChain 1 finished in 0.2 seconds.\n\nf1$summary(variables = c(\"a\"))\n\n# A tibble: 1 × 10\n  variable  mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 a        0.314  0.314 0.0205 0.0191 0.279 0.348 0.999     279.     525.\n\npost &lt;- data.table(f1$draws(variables = \"a\", format = \"matrix\"))\nhist(post$a)\n\n\n\n\n\n\n\n\n\n\nReferences"
  },
  {
    "objectID": "notebooks/robust-errors.html",
    "href": "notebooks/robust-errors.html",
    "title": "Robust errors for estimating proportion",
    "section": "",
    "text": "The goto approach for estimating an uncertainty interval for a proportion is to use the normal approximation of the binomial distribution:\n\\[\n\\begin{aligned}\n\\hat{p} \\pm z_{(1 - \\alpha)/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n\\end{aligned}\n\\]\nwhere \\(n\\) is the sample size, \\(\\hat{p}\\) is the observed sample proportion and \\(z\\) is the standard normal quantile (and typically set to \\(\\approx 2\\)).\nSay we had multiple estimates of the proportion, e.g. number of times we observe antimicrobial resistance out of the positive blood cultures we collected over the previous year. These estimates might come from differing hospitals and some might include repeat tests on individuals. This means that we have multiple levels of variation to deal with. One approach is to use a robust (sometimes call a Hubert White or sandwich) estimator for the standard errors.\nThis can be achieved by fitting a standard glm and then making an adjustment to the standard errors using the tools provided in the R sandwich package.\nSimulate data for 500 patients from 10 sites, some patients having repeat measures.\n\nlibrary(sandwich)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(marginaleffects)\nlibrary(lme4)\n\nLoading required package: Matrix\n\n# library(gee)\nlibrary(\"geepack\")\n\n# N unique pts on which we have multiple obs, each pt nested within one of\n# the 10 sites\nN &lt;- 500\nN_site &lt;- 10\np_site &lt;- as.numeric(extraDistr::rdirichlet(1, rep(1, 10)))\nsites &lt;- sample(1:N_site, N, replace = T, prob = p_site)\nd_pt &lt;- data.table(\n  id_pt = 1:N,\n  site = sort(sites)\n)\n# number obs per pt - inflated here to make a point\nn_obs &lt;- rpois(N, 2)\nd &lt;- d_pt[unlist(lapply(1:N, function(x){\n  rep(x, n_obs[x])\n}))]\nd[, id_obs := 1:.N, keyby = id_pt]\n\n# about 60% (plogis(0.4)) resistant but with site and subject level\n# variability beyond the natural sampling variability due to varying \n# number of subjects per site\nnu &lt;- rnorm(N, 0, 0.5)\n# treat site as true fixed effect\nrho &lt;- rnorm(N_site, 0, 0.7)\nd[, eta := 0.4 + rho[site] + nu[id_pt]]\n\nd[, y := rbinom(.N, 1, plogis(eta))]\nd[, site := factor(site)]\nd[, id_pt := factor(id_pt)]\n\np_obs &lt;- d[, sum(y)/.N]\n\n# d[, .(y = sum(y), n = .N)]\n# distribution of frequency of observations on a pt\n# hist(d[, .N, keyby = id_pt][, N])\n\nThe raw numbers of observations at each site are shown in Figure 1.\n\nd_fig &lt;- copy(d)\nd_fig[y == 0, resp := \"Susceptible\"]\nd_fig[y == 1, resp := \"Resistant\"]\nggplot(d_fig, aes(x = site, fill = resp)) +\n  geom_bar() +\n  scale_fill_discrete(\"\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nFigure 1: Observations by site\n\n\n\n\n\nOverall, the observed proportion resistant to antibiotics is 0.604. Various ways exist to estimate the uncertainty.\nThe wald estimate for the uncertainty interval is calculated as:\n\n# wald (normal approximation)\nse_wald &lt;- sqrt(p_obs * (1-p_obs) / nrow(d))\np_0_lb &lt;- p_obs - qnorm(0.975) * se_wald\np_0_ub &lt;- p_obs + qnorm(0.975) * se_wald\n\nA GLM with only an intercept term will give the same prediction as the observed proportion and we can calculate the naive estimate of uncertainty as:\n\n# standard glm, not accounting for pt\nf1 &lt;- glm(y ~ 1, family = binomial, data = d)\n\npredict(f1, type = \"response\")[1]\n\n        1 \n0.6040462 \n\n# get naive standard errors\ns_f1 &lt;- summary(f1)$coef\n\n# model uncertainty naive\nlo_1 &lt;- qlogis(p_obs)\n# se from intercept term, i.e. we are just looking at the 'average' or\n# typical pt, over which we would expect heterogeneity\np_1_lb &lt;- plogis(lo_1 - qnorm(0.975) * s_f1[1, 2])\np_1_ub &lt;- plogis(lo_1 + qnorm(0.975) * s_f1[1, 2])\n\nWe can use the sandwich estimator to adjuste for heterogeneity as:\n\n# adjusted to account for heterogeneity due to site (we did not \n# adjust for site in the model) and repeat measure for pt\nsw_se &lt;- sqrt(vcovCL(f1, cluster = d[, .(site, id_pt)], type = \"HC1\")[1,1])\np_2_lb &lt;- plogis(lo_1 - qnorm(0.975) * sw_se)\np_2_ub &lt;- plogis(lo_1 + qnorm(0.975) * sw_se)\n\n\nf2 &lt;- glmer(y ~ (1|site) + (1|id_pt), data = d, family = binomial)\n\nNote that in the glmer model (with a non-linear link function) the predictions are first made on the link scale, averaged, and then back transformed. This means that the average prediction may not be exactly identical to the average of predictions.\nYou’ll note that the point estimate from the glmer deviates from the observed proportion. This can be for all of the following reasons:\n\nThe GLMM provides subject-specific estimates, conditional on the random effects.\nGLMMs involve shrinkage, where estimates for groups with less data are pulled towards the overall mean.\nLarger random effects can lead to bigger differences.\nThe GLMM estimate is a model-based estimate that accounts for the hierarchical structure of the data and provides a framework for inference.\n\nIn theory, a GEE could also be used but in R the GEE framework is not particularly well set up for multiple levels of clustering.\n\nsprintf(\"%.4f (%.4f, %.4f)\", p_obs, p_0_lb, p_0_ub)\n\n[1] \"0.6040 (0.5743, 0.6338)\"\n\n# Model based adjusting for site.\nsprintf(\"%.4f (%.4f, %.4f)\", p_obs, p_1_lb, p_1_ub)\n\n[1] \"0.6040 (0.5739, 0.6334)\"\n\n# Adjusted - account for heterogeneity due to site (we did not \n# adjust for site) and repeat measure for pt\nsprintf(\"%.4f (%.4f, %.4f)\", p_obs, p_2_lb, p_2_ub)\n\n[1] \"0.6040 (0.4636, 0.7292)\"\n\n# Finally a random effects model\navg_predictions(f2, re.form = NA, type = \"link\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S 2.5 % 97.5 %\n    0.717       0.26 2.76   0.0058 7.4 0.208   1.23\n\nColumns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  link \n\navg_predictions(f2, re.form = NA, type = \"response\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)     S 2.5 % 97.5 %\n    0.672     0.0573 11.7   &lt;0.001 103.1  0.56  0.784\n\nColumns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n## Step 1\npred &lt;- predictions(f2, type = \"link\", re.form = NA)$estimate\n## Step 2: average\nplogis(mean(pred))\n\n[1] 0.6719573\n\n\n\nReferences"
  },
  {
    "objectID": "notebooks/door-1.html",
    "href": "notebooks/door-1.html",
    "title": "Desirability of Outcome Ranking (DOOR)",
    "section": "",
    "text": "DOOR analyses are claimed to be more patient centric. Instead of constructing summary measures by group for each outcome, the DOOR approach combines endpoints at a patient level and then creates a summary measure of the composite view for each intervention.\nThere are two approaches to a DOOR analysis, see [1]. The first approach uses the pairwise comparisons as introduced in Mann-Whitney-U. However, unlike the classical MWU, in the DOOR analysis, all the paired results are incorporated into the test statistic (this can also be done in MWU but wasn’t discussed in the earlier post). The other method used for the DOOR is a partial credit approach, but I do not really understand what that is about.\nAs a result, the DOOR analysis gives you an estimate of the probability that a randomly selected patient in the experimental group will have a better ranking than a randomly selected patient in the control group. The calculation used for the aggregated pairwise comparisons is:\n\\[\n\\begin{aligned}\n\\text{Pr}(door) = \\frac{ (n_{win} + 0.5 n_{tie}) } { n_e n_c }\n\\end{aligned}\n\\]\nwhere \\(n_{win}\\) is the number of times the units in the experimental group had better outcomes compared to the control group, \\(n_{tie}\\) is the number of ties, \\(n_e\\) is the number of units in the experimental group and \\(n_c\\) the number of units in the control group. This measure is also referred to as the probabilistic index [2] or probability of superiority, which will be cover in a separate post.\nIf there is no difference between the two arms, the probability will be close to 50%. Uncertainty intervals can be obtained via bootstrap or other means.\n\n\nLoading required package: Rcpp\n\n\nBuyseTest version 3.0.4\n\n\n\n\nTable 1: Ranking criteria for desirability of outcome for PJI\n\n\n\n\n\n\n\n\n\nRank\nAlive\nJoint Function\nTrt Success\nQoL\n\n\n\n\n1\nYes\nGood\nYes\nTiebreaker based on EQ5D5L\n\n\n2\nYes\nGood\nNo\nTiebreaker based on EQ5D5L\n\n\n3\nYes\nPoor1\nYes\nTiebreaker based on EQ5D5L\n\n\n4\nYes\nPoor\nNo\nTiebreaker based on EQ5D5L\n\n\n5\nNo\n-\n-\n-\n\n\n\n1\nGood joint function is based on thresholds related to patient reported success. A successful outcome at 12-months will be defined for knee PJI with an Oxford Knee Score (OKS) at 12 months of &gt;36 or an improvement (delta) from baseline of &gt;9 and for hip PJI as a Oxford Hip Score (OHS) of &gt;38 or an improvement of &gt;12 (35).\n\n\n\n\n\n\n\n\n\n\n\nConsider a DOOR schema and ranking specification for prosthetic joint infection as per Table 1. Patients are assessed and assigned ranks based on how they align with the schema with the goal of differentiating the overall or global outcome of a patient state.\nBelow 100 people per group are simulated based on some hypothetical pair of distributions for the schema. The door probability is computed along with its confidence interval (by bootstrapping):\n\nseed &lt;- 1\nset.seed(seed)\n\nn_e &lt;- 100\nn_c &lt;- 100\np_x_e &lt;- c(0.5, 0.3, 0.1, 0.1, 0.0)\np_x_c &lt;- c(0.3, 0.2, 0.2, 0.2, 0.1)\n  \nx_e &lt;- sample(1:5, n_e, replace = T, p_x_e)\nx_c &lt;- sample(1:5, n_c, replace = T, p_x_c)  \n\nn_win &lt;- 0\nn_tie &lt;- 0\nfor(i in 1:n_e){\n  for(j in 1:n_c){\n    if(x_e[i] &lt; x_c[j]) n_win &lt;- n_win + 1\n    if(x_e[i] == x_c[j]) n_tie &lt;- n_tie + 1\n  }\n}\n\n# estimate for door\npr_door &lt;- (n_win + 0.5 * n_tie)/(n_e*n_c)\n\nboot_door &lt;- function(ix_e, ix_c){\n  \n  x_e_new &lt;- x_e[ix_e]\n  x_c_new &lt;- x_c[ix_e]\n  \n  n_win &lt;- 0\n  n_tie &lt;- 0\n  for(i in 1:n_e){\n    for(j in 1:n_c){\n      if(x_e_new[i] &lt; x_c_new[j]) n_win &lt;- n_win + 1\n      if(x_e_new[i] == x_c_new[j]) n_tie &lt;- n_tie + 1\n    }\n  }\n  \n  (n_win + 0.5 * n_tie)/(n_e*n_c)\n}\n\nn_boot &lt;- 1000\npr_door_rep &lt;- numeric(n_boot)\nfor(i in 1:n_boot){\n  ix_e &lt;- sample(1:n_e, size = n_e, replace = T)\n  ix_c &lt;- sample(1:n_c, size = n_c, replace = T)\n  pr_door_rep[i] &lt;- boot_door(ix_e, ix_c)\n}\n# \ndoor_ci &lt;- quantile(pr_door_rep, probs = c(0.025, 0.975))\n\n# c(pr_door, door_ci)\n\nFrom above, the estimate for the door probability is 0.70 with a (bootstrapped) 95% CI of 0.63, 0.77.\nThe process is simple but the procedure itself does not readily admit to complex modelling. However, Follmann proposed using a logistic regression for the probability of superiority for each determinate pair of patients \\(i\\), \\(j\\) and covariate vectors \\(\\vec{z}_{ij} = \\vec{z}_i - \\vec{z}_j\\) such that the parameters in the model correspond to the log-odds that a patient with \\(\\vec{z}_i\\) has an outcome that is better than a patient with \\(\\vec{z}_j\\) [3]. The presentation from Follmann is pretty convoluted and I lost patience with it. The exposition of probabilistic index models by De Schryver, which is analogous, if not equivalent, is much clearer and will be discussed separately, Probabilistic Index Models.\nA shiny application for door analyses can be found at DOOR although it does not give any detail on the implementation of the methods used. Under the probability-based analysis tab, the overall door and then a decomposition based on each of the dichotomous door components is shown.\nScraping the source data of the site, you can at least recreate some of the statistics. For example, the door probabilities for the ARLG CRACKLE-I demo data as detailed in the door probability-based analysis tab, are replicated below for discharge from hospital:\n\n\n\n\nTable 2: Colistin data from shiny application for DOOR\n\n\n\n\n\n\n\n\n\ntrt\ndoor_num\ndoor_txt\nN\n\n\n\n\nCAZ-AVB\n1\nDischarged home\n6\n\n\nCAZ-AVB\n2\nAlive in hosp, discharged not to home, no renal failure\n17\n\n\nCAZ-AVB\n3\nAlive in hosp, discharged not to home, renal failure\n1\n\n\nCAZ-AVB\n4\nHospital death\n2\n\n\nColistin\n1\nDischarged home\n4\n\n\nColistin\n2\nAlive in hosp, discharged not to home, no renal failure\n25\n\n\nColistin\n3\nAlive in hosp, discharged not to home, renal failure\n5\n\n\nColistin\n4\nHospital death\n12\n\n\n\n\n\n\n\n\n\n\n\nn_e &lt;- d[trt == \"CAZ-AVB\", .N]\nn_c &lt;- d[trt == \"Colistin\", .N]\n\nn_win &lt;- 0\nn_tie &lt;- 0\nfor(i in 1:n_e){\n  for(j in 1:n_c){\n    if(d[trt == \"CAZ-AVB\"][i, discharge_num] &lt; \n       d[trt == \"Colistin\"][j, discharge_num]) n_win &lt;- n_win + 1\n    if(d[trt == \"CAZ-AVB\"][i, discharge_num] == \n       d[trt == \"Colistin\"][j, discharge_num]) n_tie &lt;- n_tie + 1\n  }\n}\npr_door_colistin &lt;- (n_win + 0.5 * n_tie)/(n_e*n_c)\n\n\nboot_door &lt;- function(ix_e, ix_c){\n  \n  x_e_new &lt;- d[trt == \"CAZ-AVB\"][ix_e, discharge_num]\n  x_c_new &lt;- d[trt == \"Colistin\"][ix_c, discharge_num]\n  \n  n_win &lt;- 0\n  n_tie &lt;- 0\n  for(i in 1:n_e){\n    for(j in 1:n_c){\n      if(x_e_new[i] &lt; x_c_new[j]) n_win &lt;- n_win + 1\n      if(x_e_new[i] == x_c_new[j]) n_tie &lt;- n_tie + 1\n    }\n  }\n  \n  (n_win + 0.5 * n_tie)/(n_e*n_c)\n}\n\nn_boot &lt;- 1e3\npr_door_rep &lt;- numeric(n_boot)\nfor(i in 1:n_boot){\n  ix_e &lt;- sample(1:n_e, size = n_e, replace = T)\n  ix_c &lt;- sample(1:n_c, size = n_c, replace = T)\n  pr_door_rep[i] &lt;- boot_door(ix_e, ix_c)\n}\npr_door_colistin_ci &lt;- quantile(pr_door_rep, probs = c(0.025, 0.975))\n\nGiving 0.57 and 95% CI of 0.49, 0.66.\nSimilarly, for renal failure:\n\nd[, .N, keyby = .(trt, renal_num, renal_txt)]\n\nKey: &lt;trt, renal_num, renal_txt&gt;\n        trt renal_num renal_txt     N\n     &lt;char&gt;     &lt;int&gt;    &lt;char&gt; &lt;int&gt;\n1:  CAZ-AVB         0        No    25\n2:  CAZ-AVB         1       Yes     1\n3: Colistin         0        No    39\n4: Colistin         1       Yes     7\n\nn_win &lt;- 0\nn_tie &lt;- 0\nfor(i in 1:n_e){\n  for(j in 1:n_c){\n    if(d[trt == \"CAZ-AVB\"][i, renal_num] &lt; \n       d[trt == \"Colistin\"][j, renal_num]) n_win &lt;- n_win + 1\n    if(d[trt == \"CAZ-AVB\"][i, renal_num] == \n       d[trt == \"Colistin\"][j, renal_num]) n_tie &lt;- n_tie + 1\n  }\n}\npr_door_colistin &lt;- (n_win + 0.5 * n_tie)/(n_e*n_c)\n\nwhich gives 0.56 aligning with the shiny app results.\n\nGeneralised pairwise comparisons\nGPC is a related method and frankly it seems a bit better thought out than DOOR, but I am not sure that it is as popular [4]. The outcomes of interest are first ranked in terms of importance and the pairwise comparison is run progressively on each outcome for all pairs. For the ties under each outcome, the procedure moves on to the outcome that has the next highest priority and so on.\nWhile GPC can be used to produce a range of summary measures, the original paper used net treatment benefit (NTB).\n\\[\n\\begin{aligned}\nNTB = \\frac{ (n_{win} - n_{loss}) } { n_{win} + n_{loss} + n_{tie} }\n\\end{aligned}\n\\]\nwhere \\(n_{win} + n_{loss} + n_{tie}\\) is typically equal to the total number of pairwise comparisons.\nUnlike the DOOR approach, GPC allows for component level contribution and event level correlation. In contrast to the Win Ratio, the net treatment benefit incorporates ties.\nAs an example, consider a situation where we have outcomes, as above, for death, joint function, treatment success and QoL. The procedure first runs pairwise comparisons for all units on death and the number of wins, draws and losses recorded, demonstration below.\n\nset.seed(seed)\nN &lt;- 100\nd &lt;- data.table(\n  id = 1:(2*N),\n  # expt is 1\n  trt = rep(1:0, each = N)\n)\nd[, death := rbinom(.N, 1, prob = 0.4 - 0.2 * trt)]\nd[, jf := rbinom(.N, 1, prob = 0.6 - 0 * trt)]\nd[, success := rbinom(.N, 1, prob = 0.65 + 0.15 * trt)]\nd[, qol := rnorm(.N, 0 + 0.4 * trt, 1)]\n\nn_e &lt;- d[trt == 1, .N]\nn_c &lt;- d[trt == 0, .N]\nn_win &lt;- numeric(4)\nn_loss &lt;- numeric(4)\nn_tie &lt;- numeric(4)\n\n# create a grid to compute all comparisons (quicker than looping)\nsetkey(d, id)\nd_all &lt;- CJ(i = 1:100, j = 100 + (1:100))\n# death\nd_all[, death_i := d[i, death]]\nd_all[, death_j := d[j, death]]\n# note sign direction differs dependent on context of comparison\nd_all[death_i &lt; death_j, death_res := 1]\nd_all[death_i &gt; death_j, death_res := -1]\nd_all[death_i == death_j, death_res := 0]\n# jf\nd_all[, jf_i := d[i, jf]]\nd_all[, jf_j := d[j, jf]]\nd_all[jf_i &gt; jf_j, jf_res := 1]\nd_all[jf_i &lt; jf_j, jf_res := -1]\nd_all[jf_i == jf_j, jf_res := 0]\n# success\nd_all[, success_i := d[i, success]]\nd_all[, success_j := d[j, success]]\nd_all[success_i &gt; success_j,  success_res := 1]\nd_all[success_i &lt; success_j,  success_res := -1]\nd_all[success_i == success_j, success_res := 0]\n# success\nd_all[, qol_i := d[i, qol]]\nd_all[, qol_j := d[j, qol]]\nd_all[qol_i &gt;  qol_j, qol_res := 1]\nd_all[qol_i &lt;  qol_j, qol_res := -1]\nd_all[qol_i == qol_j, qol_res := 0]\nhead(d_all)\n\nKey: &lt;i, j&gt;\n       i     j death_i death_j death_res  jf_i  jf_j jf_res success_i success_j\n   &lt;int&gt; &lt;num&gt;   &lt;int&gt;   &lt;int&gt;     &lt;num&gt; &lt;int&gt; &lt;int&gt;  &lt;num&gt;     &lt;int&gt;     &lt;int&gt;\n1:     1   101       0       1         1     1     0      1         1         1\n2:     1   102       0       0         0     1     1      0         1         0\n3:     1   103       0       0         0     1     1      0         1         0\n4:     1   104       0       1         1     1     1      0         1         0\n5:     1   105       0       1         1     1     1      0         1         1\n6:     1   106       0       0         0     1     0      1         1         0\n   success_res    qol_i      qol_j qol_res\n         &lt;num&gt;    &lt;num&gt;      &lt;num&gt;   &lt;num&gt;\n1:           0 1.293674  1.0744410       1\n2:           1 1.293674  1.8956548      -1\n3:           1 1.293674 -0.6029973       1\n4:           1 1.293674 -0.3908678       1\n5:           0 1.293674 -0.4162220       1\n6:           1 1.293674 -0.3756574       1\n\n\nGPC calculations:\n\n# ntb on death is as follows:\nntb &lt;- numeric(4)\nnames(ntb) &lt;- c(\"death\", \"jf\", \"success\", \"qol\")\nd_res &lt;- d_all[, .N, keyby = death_res]\nd_res[, pct := N / nrow(d_all)]\n\nntb[\"death\"] &lt;- (d_res[death_res == 1, N] - d_res[death_res == -1, N]) /  nrow(d_all)\n\n# for the ties on death, compute jf:\nd_res &lt;- d_all[death_res == 0, .N, keyby = jf_res]\nd_res[, pct := N / nrow(d_all)]\nntb[\"jf\"] &lt;- (d_res[jf_res == 1, N] - d_res[jf_res == -1, N]) /  nrow(d_all)\n\n# for comparisons on all pairs, don't condition:\n# d_res &lt;- d_all[, .N, keyby = jf_res]\n# d_res[, pct := N / nrow(d_all)]\n# d_res\n# (d_res[jf_res == 1, N] - d_res[jf_res == -1, N]) /  nrow(d_all)\n\n# for the ties on death and jf, compute success:\nd_res &lt;- d_all[death_res == 0 & jf_res == 0, .N, keyby = success_res]\nd_res[, pct := N / nrow(d_all)]\nntb[\"success\"] &lt;- (d_res[success_res == 1, N] - d_res[success_res == -1, N]) / nrow(d_all)\n\n# for the ties on death, jf and success, compute qol:\nd_res &lt;- d_all[death_res == 0 & jf_res == 0 & success_res == 0, .N, keyby = qol_res]\nd_res[, pct := N / nrow(d_all)]\nntb[\"qol\"] &lt;- (d_res[qol_res == 1, N] - d_res[qol_res == -1, N]) / nrow(d_all)\n\nNote that for all endpoints, we use the total number of pairwise comparisons as the denominator and not the number of ties left over from the previous outcome.\nThe resulting net treatment benefit reported on each outcome:\n\nntb\n\n  death      jf success     qol \n 0.2300  0.0527  0.0574  0.0455 \n\n\nTaking the cumulative sum, progresses from the effect of each component through to an overall effect:\n\ncumsum(ntb)\n\n  death      jf success     qol \n 0.2300  0.2827  0.3401  0.3856 \n\n\nThe NTB is absolute measure ranging from -1 to 1 with zero being no effect. It estimates the probability that a random unit on the expt arm will do better than a random unit on the control arm minus the probability that a random unit on the control arm will do better than a random unit on the expt arm. For example, if \\(Pr(E&gt;C) = 0.7\\), then \\(Pr(E&lt;C) = 0.3\\) and \\(NTB = 0.7 - 0.3 = 0.4\\).\nYou can compute the overall effect directly with the following:\n\nn_win &lt;- d_all[death_res == 1, .N] + d_all[death_res == 0 & jf_res == 1, .N] +\n   + d_all[death_res == 0 & jf_res == 0 & success_res == 1, .N] +\n   + d_all[death_res == 0 & jf_res == 0 & success_res == 0 & qol_res == 1, .N]\n\nn_loss &lt;- d_all[death_res == -1, .N] + d_all[death_res == 0 & jf_res == -1, .N] +\n   + d_all[death_res == 0 & jf_res == 0 & success_res == -1, .N] +\n   + d_all[death_res == 0 & jf_res == 0 & success_res == 0 & qol_res == -1, .N]\n\n# n_ties &lt;- d_all[death_res == 0 & jf_res == 0 & success_res == 0, .N] \n\n(n_win - n_loss) / nrow(d_all)\n\n[1] 0.3856\n\n\nThe NTB is known to be the inverse of the number needed to treat, i.e. 1/ number of pt you need to trt to avoid one bad outcome. For large samples, inference can again be conducted via bootstrap. R provides the BuyseTest package that allows for stratification (beyond the implicit treatment level stratification).\n\nff1 &lt;- trt ~ bin(death, operator = \"&lt;0\") + bin(jf) + bin(success) + cont(qol)\nf1 &lt;- BuyseTest(ff1, data = d, trace = 0)\ns_f1 &lt;- summary(f1)\n\n       Generalized pairwise comparisons with 4 prioritized endpoints\n\n - statistic       : net treatment benefit  (delta: endpoint specific, Delta: global) \n - null hypothesis : Delta == 0 \n - confidence level: 0.95 \n - inference       : H-projection of order 1 after atanh transformation \n - treatment groups: 1 (treatment) vs. 0 (control) \n - neutral pairs   : re-analyzed using lower priority endpoints\n - results\n endpoint total(%) favorable(%) unfavorable(%) neutral(%) uninf(%)  delta\n    death   100.00        33.20          10.20      56.60        0 0.2300\n       jf    56.60        15.30          10.03      31.27        0 0.0527\n  success    31.27         9.86           4.12      17.29        0 0.0574\n      qol    17.29        10.92           6.37       0.00        0 0.0455\n  Delta CI [2.5% ; 97.5%]    p.value    \n 0.2300    [0.106;0.3469] 0.00032703 ***\n 0.2827   [0.1355;0.4177] 0.00022230 ***\n 0.3401   [0.1882;0.4761] 2.2250e-05 ***\n 0.3856     [0.2326;0.52] 2.6463e-06 ***\n\n\nIn the results, the totals, wins, loss and ties are presented as percentages rather than counts. For example, the total column effectively represents the proportion of pairs that carry over from one outcome to the next; for death there were 5660 pairs that carried over to joint function there were 3127 pairs that carried over to the treatment success outcome and so on. These can be visualised as:\n\nd_fig &lt;- data.table(s_f1)\nd_fig &lt;- d_fig[, 1:5]\nnames(d_fig) &lt;- c(\n  \"endpoint\", \"total\", \"wins\", \"losses\", \"tie\"\n)\nd_fig &lt;- melt(d_fig, id.vars = \"endpoint\")\nd_fig &lt;- d_fig[variable != \"total\"]\n\nggplot(d_fig, aes(x = endpoint, y = value, fill = variable)) +\n  geom_bar(stat='identity') +\n  scale_fill_discrete(\"\") +\n  scale_y_continuous(\"Percentage\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nFigure 1: Contribution by each endpoint\n\n\n\n\n\nInference can be conducted on all pairs for all outcomes by indicating that the hierarchical perspective is not required:\n\nf2 &lt;- BuyseTest(ff1, hierarchical = FALSE, data = d, trace = 0)\nsummary(f2)\n\n       Generalized pairwise comparisons with 4 endpoints\n\n - statistic       : net treatment benefit  (delta: endpoint specific, Delta: global) \n - null hypothesis : Delta == 0 \n - confidence level: 0.95 \n - inference       : H-projection of order 1 after atanh transformation \n - treatment groups: 1 (treatment) vs. 0 (control) \n - results\n endpoint weight total(%) favorable(%) unfavorable(%) neutral(%) uninf(%)\n    death   0.25      100        33.20          10.20      56.60        0\n       jf   0.25      100        26.64          17.64      55.72        0\n  success   0.25      100        30.80          13.80      55.40        0\n      qol   0.25      100        64.02          35.98       0.00        0\n  delta  Delta CI [2.5% ; 97.5%]    p.value    \n 0.2300 0.0575   [0.0272;0.0877] 0.00020121 ***\n 0.0900 0.0800    [0.037;0.1227] 0.00026848 ***\n 0.1700 0.1225   [0.0699;0.1744] 5.4724e-06 ***\n 0.2804 0.1926    [0.1296;0.254] 3.3839e-09 ***\n\n\n\n\nReferences\n\n\n1. Chamberlain J. Desirability of outcome ranking for status epilepticus. Research Methods in Neurology. 2023;101.\n\n\n2. De Schryver M. A tutorial on probabilistic index models: Regression models for the effect size p(Y1 &gt; Y2). American Psychological Association. 2019;24.\n\n\n3. Follmann D. Regression analysis based on pairwise ordering of patients’ clinical histories. Statistics in Medicine. 2002;21.\n\n\n4. Buyse M. Generalized pairwise comparisons of prioritized outcomes in the two-sample problem. Statistics in Medicine. 2010;29."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Biostatistician working mostly in the area of Bayesian adaptive clinical trials using R and stan. The site contains various posts/reminders on topics that are relevant to my day-to-day work."
  },
  {
    "objectID": "about.html#repository-status",
    "href": "about.html#repository-status",
    "title": "About",
    "section": "Repository status",
    "text": "Repository status\n\nlibrary(git2r)\nrepo &lt;- git2r::repository(path = \".\")\nsummary(repo)\n\nLocal:    main /Users/mark/Documents/project/website/src/maj-biostat.github.io\nRemote:   main @ origin (https://github.com/maj-biostat/maj-biostat.github.io)\nHead:     [4151fa9] 2024-09-30: Probabilistic index wip\n\nBranches:         1\nTags:             0\nCommits:         19\nContributors:     2\nStashes:          0\nIgnored files:    2\nUntracked files: 11\nUnstaged files:  34\nStaged files:     0\n\nLatest commits:\n[4151fa9] 2024-09-30: Probabilistic index wip\n[b0555ab] 2024-09-27: Convert auto date to manual\n[263c271] 2024-09-27: update door\n[f9c6330] 2024-09-25: Update site\n[20fb295] 2024-09-25: Update site"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "maj-biostat.github.io",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n\n\n\n2024-09-27\n\n\nDesirability of Outcome Ranking (DOOR)\n\n\n12 min\n\n\n\n\n\n\n\n2024-09-25\n\n\nMann-Whitney U\n\n\n14 min\n\n\n\n\n\n\n\n2024-09-30\n\n\nProbabilistic Index Models\n\n\n4 min\n\n\n\n\n\n\n\n2024-09-18\n\n\nRandom walk priors\n\n\n3 min\n\n\n\n\n\n\n\n2024-09-25\n\n\nRobust errors for estimating proportion\n\n\n4 min\n\n\n\n\n\n\n\n2024-09-25\n\n\nUser-defined Probability Distributions in Stan\n\n\n2 min\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "notebooks/random-walk-prior.html",
    "href": "notebooks/random-walk-prior.html",
    "title": "Random walk priors",
    "section": "",
    "text": "First order random walk\nFor regular spacings, a first-order random walk prior can be specified as:\n\\[\n\\begin{aligned}\n\\eta_0 &\\sim \\text{Logistic}(0,1) \\\\\n\\delta &\\sim \\text{Normal}(0, 1) \\\\\n\\sigma_\\delta &\\sim \\text{Exponential}(1) \\\\\n\\eta_{[1]} &= \\eta_0 \\\\\n\\eta_{[k]} &= \\sum_{i = 2}^{N}(\\eta_{[k-1]}  + \\delta  \\sigma_\\delta) \\\\\n\\end{aligned}\n\\]\nSimulate data from an oscillator:\n\nlibrary(data.table)\nlibrary(ggplot2)\n\nset.seed(2)\nd_obs &lt;- data.table(\n  x = sort(runif(100, 0, 2*pi))\n)\nd_obs[, eta := sin(x)]\nd_obs[, n := rpois(.N, 200)]\nd_obs[, y := rbinom(.N, n, plogis(eta))]\n\n# we only observe 30% of the data generated\nd_obs[, y_mis := rbinom(.N, 1, 0.7)]\n\nNaive implementation of a first order random walk in stan.\n\n\ndata {    \n  int N; \n  // the way the model is set up it does not matter if some of the n's are\n  // zero because the likelihood uses y_sub, which is obtained by reference\n  // to the missing indicator y_mis, which explicitly says that there were\n  // no observations at the given value of x.\n  array[N] int y;    \n  array[N] int n;    \n  vector[N] x;    \n  array[N] int y_mis; \n  \n  int prior_only;    \n  \n  // priors\n  real r_nu;\n  \n}    \ntransformed data {\n  // x_diff gives us the variable spacing in x and allows us to scale\n  // the variance appropriately\n  vector[N-1] x_diff;\n  // the number of observations we truly had once missingness is accounted for\n  int N_sub = N - sum(y_mis);\n  // our truly observed responses (successes) and trials\n  array[N_sub] int y_sub;\n  array[N_sub] int n_sub;\n  // \n  for(i in 1:(N-1)){x_diff[i] = x[i+1] - x[i];}\n  // go through the data that was passed in and build the data on which \n  // we will fit the model\n  int j = 1;\n  for(i in 1:N){\n    if(y_mis[i] == 0){\n      y_sub[j] = y[i];\n      n_sub[j] = n[i];\n      j += 1;\n    }\n  }  \n}\nparameters{  \n  // the first response\n  real b0;    \n  // offsets\n  vector[N-1] delta;    \n  // how variable the response is\n  real&lt;lower=0&gt; nu;   \n}    \ntransformed parameters{    \n  // the complete modelled mean response\n  vector[N] e; \n  // this is the variance scaled for the distance between each x\n  // note this is truly a variance and not an sd\n  vector[N-1] tau;    \n  // \n  vector[N_sub] eta_sub;    \n  // adjust the variance for the distance b/w doses    \n  // note that nu is squared to turn it into variance\n  for(i in 2:N){tau[i-1] = x_diff[i-1]*pow(nu, 2);}    \n  // resp is random walk with missingness filled in due to the \n  // dependency in the prior\n  e[1] = b0;    \n  // each subsequent observation has a mean equal to the previous one\n  // plus some normal deviation with mean zero and variance calibrated for\n  // the distance between subsequent observations.\n  for(i in 2:N){e[i] = e[i-1] + delta[i-1] * sqrt(tau[i-1]);}    \n  // eta_sub is what gets passed to the likelihood\n  { \n    int k = 1;\n    for(i in 1:N){\n      if(y_mis[i] == 0){\n        eta_sub[k] = e[i];\n        k += 1;\n      }\n    }\n  }\n}    \nmodel{    \n  // prior on initial response\n  target += logistic_lpdf(b0 | 0, 1);\n  // prior on sd\n  target += exponential_lpdf(nu | r_nu);\n  // standard normal prior on the offsets\n  target += normal_lpdf(delta | 0, 1);    \n  if(!prior_only){target += binomial_logit_lpmf(y_sub | n_sub, eta_sub);}    \n}    \ngenerated quantities{    \n  // predicted values at each value of x\n  vector[N] p;    \n  vector[N-1] e_diff;    \n  vector[N-1] e_grad;    \n  // compute diffs\n  for(i in 1:(N-1)){e_diff[i] = e[i+1] - e[i];}\n  e_grad = e_diff ./ x_diff;\n  p = inv_logit(e);\n}    \n\n\n\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/random-walk-01.stan\")\n\n\nld = list(\n  N = nrow(d_obs), \n  y = d_obs[, y], \n  n = d_obs[, n],\n  x = d_obs[, x], \n  y_mis = d_obs[, y_mis], \n  prior_only = F, \n  r_nu =  3\n  )\n\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 1, chains = 1, refresh = 0, show_exceptions = F,\n  max_treedepth = 10)\n\nRunning MCMC with 1 chain...\n\nChain 1 finished in 2.9 seconds.\n\n\nWarning: 2 of 2000 (0.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\nf1$summary(variables = c(\"nu\"))\n\n# A tibble: 1 × 10\n  variable  mean median    sd    mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 nu       0.533  0.519 0.103 0.0946 0.392 0.722  1.00    1221.    1114.\n\n\nRepresentation of output.\n\nd_out &lt;- data.table(f1$draws(variables = \"p\", format = \"matrix\"))\n\nd_fig &lt;- melt(d_out, measure.vars = names(d_out))\nd_fig &lt;- d_fig[, .(\n  mu = mean(value), \n  q_025 = quantile(value, prob = 0.025),\n  q_975 = quantile(value, prob = 0.975)\n), keyby = variable]\nd_fig[, ix := gsub(\"p[\", \"\", variable, fixed = T)]\nd_fig[, ix := as.numeric(gsub(\"]\", \"\", ix, fixed = T))]\nd_fig[, x := d_obs[ix, x]]\n\n\nggplot(d_obs, aes(x = x, y = plogis(eta))) +\n  geom_line(lty = 1) +\n  geom_point(data = d_obs[y_mis == 0],\n             aes(x = x, y = y/n), size = 0.7) +\n  geom_point(data = d_obs[y_mis == 1],\n             aes(x = x, y = y/n), size = 0.7, pch = 2) +\n  geom_ribbon(data = d_fig, \n              aes(x = x, ymin = q_025, ymax = q_975),\n              inherit.aes = F, fill = 2, alpha = 0.3) +\n  geom_line(data = d_fig, \n              aes(x = x, y = mu), col = 2) +\n  geom_point(data = d_fig, \n              aes(x = x, y = mu), col = 2, size = 0.6) +\n  scale_x_continuous(\"x\") +\n  scale_y_continuous(\"Probability\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 1: True function (black line), data on which the model was fit (black points), data we did not see (black triangles), random walk (red line) with interpolated points (red) and uncertainty (red ribbon).\n\n\n\n\n\n\n\nSecond order random walk\nThe second order random walk for regular locations has density\n\\[\n\\begin{aligned}\n\\pi(x) \\propto \\exp\\left( -\\frac{1}{2} \\sum_{i=2}^{n-1} (x_{i-1} - 2x_i + x_{i+1})^2  \\right)\n\\end{aligned}\n\\]\nThe main term can be interpreted as an estimate of the second order derivative of a continuous time function. But this is not generally suitable for irregular spacings of x [1].\n\n\nReferences\n\n\n1. Lindgren F, Rue H. On the second-order random walk model for irregular locations. Scandinavian Journal of Statistics. 2008;35:691–700."
  },
  {
    "objectID": "notebooks/mann-whitney-u.html",
    "href": "notebooks/mann-whitney-u.html",
    "title": "Mann-Whitney U",
    "section": "",
    "text": "The MWU checks a rank sum difference between two independent groups and tests whether two groups have been drawn from the same population. It is an alternative to the t-test. But it only requires that the observations from both groups are at least ordinal such that you can discern for any two observations which one is greater (or better in some sense). In the classical interpretation, the test assumes that the distributions are identical under the null hypothesis and that they are not identical under the alternative distribution. Underlying the test is an interest in the probability that a randomly selected unit from one group fairs better than a randomly selected unit from the other. More concretely, the interest is int:\n\\[\n\\text{Pr}(X &gt; Y) \\ne \\text{Pr}(Y &gt; X)\n\\]\nand if this quantity exceeds \\(0.5\\) then, all things being equal, you would prefer assignment to the \\(X\\) group.\nOne approach to the procedure involves combining all the observations and ordering the records from best to worse (keeping track of which record belongs to which group). Each row is assigned a rank, the sum of the ranks is calculated for the first group (\\(T_1\\)) and the second group (\\(T_2\\)) and then the \\(U\\) statistics are computed as:\n\\[\n\\begin{aligned}\nU_1 &= n_1 n_2 + \\frac{n_1(n_1 + 1)}{2} - T_1 \\\\\nU_2 &= n_1 n_2 + \\frac{n_2(n_2 + 1)}{2} - T_2 \\\\\n\\end{aligned}\n\\]\nthe Mann-Whitney-U is given by \\(U = \\text{min}(U_1,U_2)\\), which is the test statistic.\nFor example, say we have units 1 to 20 in the first group and units 21 to 40 in the second with all the units in the first group having a better score than the units in the second.\n\nlibrary(data.table)\nlibrary(ggplot2)\n# contrived setup to make the scores for units ascend \n# (lower values considered better)\nd &lt;- data.table(\n  i = 1:40, score = sort(rnorm(40, 0, 1)), \n  group = rep(1:2, each = 20)\n)\nd[, rank := 1:40]\nn1 &lt;- d[group == 1, .N]\nn2 &lt;- d[group == 2, .N]\n\nNow add up the ranks for both groups.\n\n(T1 = d[group == 1, sum(rank)])\n\n[1] 210\n\n(T2 = d[group == 2, sum(rank)])\n\n[1] 610\n\n\nFrom these compute \\(U_1\\) and \\(U_2\\)\n\n(U_1 = n1*n2 + n1*(n1+1)/2 - T1)\n\n[1] 400\n\n(U_2 = n1*n2 + n2*(n2+1)/2 - T2)\n\n[1] 0\n\n\nThe above is equivalent to a pairwise comparison procedure (see later). From this, we can estimate the probability of superiority as referred to earlier (which I believe, but am not certain, is assuming that the two distributions differ only in location, not in shape) as:\n\n# here the contrived setup says that the value of x_1 and x_2 also equate to their ranks\n# and that lower values are better.\nx_1 &lt;- 1:20\nx_2 &lt;- 21:40\nn_1 &lt;- length(x_1)\nn_2 &lt;- length(x_2)\nu_1 &lt;- 0\nu_2 &lt;- 0\n\nk &lt;- 1\nfor(i in 1:length(x_1)){\n  for(j in 1:length(x_2)){\n    if(x_1[i] &lt; x_2[j]) u_1 &lt;- u_1 + 1\n    else if(x_1[i] &gt; x_2[j]) u_2 &lt;- u_2 + 1\n    k &lt;- k + 1\n  }\n}\nsprintf(\"u1 = %.0f, Pr(X&gt;Y) = %.2f, u2 = %.0f, Pr(Y&gt;X) = %.2f\", u_1, u_1/(n_1*n_2), u_2, u_2/(n_1*n_2))\n\n[1] \"u1 = 400, Pr(X&gt;Y) = 1.00, u2 = 0, Pr(Y&gt;X) = 0.00\"\n\n\nThat is, for all possible pairwise combinations, we compare the value in the first group to each value in second group and add up how often X &gt; Y and compute the probability estimate of \\(\\text(Pr)(X&gt;Y)\\) by simply dividing the number of occurrences by the total number of pairs.\nFor the test, we take the following reference points. First, under no difference, the expected value for \\(U\\) is\n\\[\n\\mathbb{E}[U] = \\frac{n_1 n_2}{2}\n\\]\nwith a standard standard error of:\n\\[\n\\sigma_U = \\sqrt{\\frac{n_1 n_2 (n_1 + n_2 + 1)}{12}}\n\\]\nUsing these, you can compute a z-value using a normal approximation (for large samples &gt; 20 per group) in the usual way by taking the observed value for \\(U\\) subtracting the expected value and dividing by the standard error:\n\\[\nz = \\frac{U - \\mu_u}{\\sigma_U}\n\\]\nand obtain a p-value for the test."
  },
  {
    "objectID": "notebooks/mann-whitney-u.html#footnotes",
    "href": "notebooks/mann-whitney-u.html#footnotes",
    "title": "Mann-Whitney U",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe intuition for the above is that \\(F_e(x)\\) gives the probability that \\(X_e\\) is greater than a specific value of \\(x\\), and \\(f_c(x) dx\\) gives the probability that \\(X_c\\) falls in a small interval around \\(x\\). The product of these terms gives the probability that \\(X_e &gt; X_c\\) for that small interval and thus integrating over all possible values of \\(x\\) gives the value we are after.↩︎"
  },
  {
    "objectID": "notebooks/probabilistic-index.html",
    "href": "notebooks/probabilistic-index.html",
    "title": "Probabilistic Index Models",
    "section": "",
    "text": "The probabilistic index (PI), also known as the probability of superiority, refers to the probability that the outcome of a randomly selected subject in the treatment group exceeds the outcome of another randomly selected subject on the control group [1]. Thus a PI of 50% indicates that a patient on the experimental treatment is as likely to be better or worse as compared with a patient on the control treatment.\nThe PI is the metric associated with the Mann-Whitney-U test (aka Wilcoxon-Mann-Whitney). When modelled under a regression framework with conditioning on the covariate values of both subjects, we have a probabilistic index model (PIM).\nIn notational terms, if we let \\(y\\) denote a univariate outcome and \\(\\vec{x}\\) a vector of covariates for a unit, then the PI is given by \\(\\text{Pr}(y_i &lt; y_j | \\vec{x_i}, \\vec{x_j})\\) where \\(i\\) and \\(j\\) denote distinct units.\nTwo things are clear from this definition:\n\nThe PI does not provide information on the magnitude of the difference between two populations.\nThe measure is always comparing two different subjects, it does not give the probability that a single patient will benefit from a given treatment as compared with the conventional treatment.\n\nIn a two-sample setting we can use the MWU to compute the probabilistic index. However, when our treatment is continuous or we wish to condition on a set of covariates then it is desirable to embed the PI into a regression model. The approach is to model the conditional PI directly as a function of covariates:\n\\[\n\\begin{aligned}\n\\text{Pr}(Y_i &lt; Y_j | X_i, X_j) = m(X_i, X_j, \\beta)\n\\end{aligned}\n\\]\nwhere \\(m(.)\\) is some user-specified function and \\((Y_i, X_i)\\) are iid and \\(X_i\\), \\(X_j\\) and \\(\\beta\\) are vector quantities. It is convenient to choose \\(m\\) as:\n\\[\n\\begin{aligned}\nm(X_i, X_j, \\beta) = g^{-1}[(X_j - X_i)^\\top \\beta]\n\\end{aligned}\n\\]\nTo interpret the regression coefficient, consider two subjects \\(i\\) and \\(j\\) with covariate patterns \\(X^\\top = (Z_1, Z_2)\\) with \\(\\beta^\\top = (\\beta_1, \\beta_2)\\) (for a bivariate case). Say, subject \\(i\\) has covariate values \\((z_1, z_2)\\) and subject \\(j\\) has values \\((z_1 + 1, z_2)\\) so that both have the same value for \\(Z_2\\) but where \\(Z_1\\) differs by one unit. It follows that:\n\\[\n\\begin{aligned}\n\\text{Pr}(Y_i &lt; Y_j | Z_{1i} = z_1, Z_{1j} = z_1 + 1, Z_{2i} = Z_{2j}) = g^{-1}{\\beta_1}\n\\end{aligned}\n\\]\nso that \\(g^{-1}{\\beta_1}\\) gives the probability that a randomly selected subject with covariate value \\(z_1\\) for \\(Z_1\\) will have a lower outcome as compared with a randomly selected subject with a covariate value that is higher by one and where \\(Z_2\\) is the same for both subjects.\n\n\n\n\n\n\nNote\n\n\n\nNotice the absence of an intercept in these models. This means that when the covariate patterns are the same, the probability that \\(Y_i\\) is less than \\(Y_j\\) is 0.5 and vice versa.\n\n\nAs might be clear, the above can be handled via a logistic regression applied to the transformed binary outcome \\(I_{ij} = I(Y_i &lt; Y_j)\\) and predictors \\(X_{ij} = X_j - X_i\\). From this, the MLE give consistent estimates for \\(\\beta\\), [2]. However, despite the fact that \\((Y_i, X_i)\\) are mutually independent, the transformed data \\(I_{ij}\\) and \\(X_{ij}\\) are not. This is obviously the case if we consider \\(I_{ij} = I(Y_i &lt; Y_j)\\) and \\(I_{ik} = I(Y_i &lt; Y_k)\\) since both share \\(Y_i\\) making them no longer independent. Moreover, the \\(I_{ij}\\) have a correlation structure that is different from the typical block correlation structure in multi-level data. Thas introduced a sandwich estimator for the standard errors (frequentist setting) implemented in the R package pim, [2] and [3]. However, a bootstrap approach could also be used - simply take \\(B\\) bootstrap samples (with replacement) of size \\(n\\) and then repeat whatever estimation process was used.\n\n\n\n\n\n\nNote\n\n\n\nThe above specification can be modified to deal with ties by modifying the transformed outcome to \\(I(Y_i &lt; Y_j) + 0.5I(Y_i = Y_j)\\).\n\n\n\nReferences\n\n\n1. De Schryver M. A tutorial on probabilistic index models: Regression models for the effect size p(Y1 &gt; Y2). American Psychological Association. 2019;24.\n\n\n2. Thas O. Probabilistic index models. Journal of the Royal Statistical Society Series B Methodological. 2012;74:623–71.\n\n\n3. Meys J. Pim fit probabilistic index models. 2017."
  }
]