[
  {
    "objectID": "notebooks/hypothetical-estimands.html",
    "href": "notebooks/hypothetical-estimands.html",
    "title": "Strategies for handling Intercurrent Events - hypothetical strategy",
    "section": "",
    "text": "Note - this is WIP - Unfinished\nThe ICH E9(R1) addendum on estimands and sensitivity analysis in clinical trials (estimand framework) advocates for an explicit definition of the causal effect of interest is advocated. The central goal is to measure how the outcome of an intervention compares to the outcome that would have happened to the same units under a different intervention. As we never see the unit level outcomes under all interventions, clinical trials employ randomisation as the structural mechanism to enable these effects to be identified.\nThe causal aspects are thus linked with randomised assignment rather than received treatment. It is, however, assumed that units will follow the assigned treatment and therefore, in the ideal case, the causal relationship can be extended to the actual taking of treatment.\nIntercurrent event (unit level events that occur after randomisation that alter the interpretation or existence of the outcome) can compromise the causal effects and thus need to be considered in the estimand definitions. The specification of the treatment regimen via the estimand definition is critical in understanding what will ultimately constitute an ICE.\nThe components of an estimand are: treatment regimen, population, outcome, intercurrent event handling and summary measure. In English, these correspond to\n\ntreatment regimen := what is the trial comparing?\npopulation := what people/condition are we trying to help?\noutcome := what is being measured?\nintercurrent event handling := how do we intend to handle treatment related events that disrupt the existence or interpretation of the outcome?\nsummary measure := what statistical measure is going to be used?\n\n\nPer protocol\nA traditional per-protocol analysis aims at offering a specific perspective on the trial results; the implicit goal is usually that of evaluating the effect of treatment in those that adhere to the protocol. However, the usual approach simply subsets the trial data to those units that have adhered and performs the primary analysis (unchanged) on that part of the data. This is insufficient to define a causal effect.\n\n\nHypothetical strategy\nA hypothetical strategy for dealing with ICEs considers a scientific question under a counterfactual condition to what actually happened.\nFor example, perhaps rescue medication was ethically necessary for a patient, but we are interested in trying to simulate what the outcome would have been in absence of the rescue medication. The hypothetical perspective may be relevant even when rescue medication is permitted under the treatment regimen (experimental drug +/- rescue vs control +/- rescue) in order that we can evaluate the results under the hypothetical scenario where our regimen was experimental drug vs control (both without rescue).\n\n\nEstimators for what would have happened in absence of ICE\nData after an ICE can be excluded from the analysis and then outcomes dealt with via maximum likelihood (in a longitudinal setting) or multiple imputation (if necessary assumptions are met). In other words, when you have repeat measures, you can run a likelihood-based repeat measures analysis fit to the data that was observed up until the rescue medication was taken or the assigned treatment was discontinued. When you don’t repeat measure data, the above doesn’t apply and all you can do is remove the observed outcome for the patient that took the rescue medication and then model based on that data, again either by ML or MI.\n\n\nReferences"
  },
  {
    "objectID": "notebooks/probabilistic-index.html",
    "href": "notebooks/probabilistic-index.html",
    "title": "Probabilistic Index Models",
    "section": "",
    "text": "The probabilistic index (PI), also known as the probability of superiority, refers to the probability that the outcome of a randomly selected subject in the treatment group exceeds the outcome of another randomly selected subject on the control group [1]. Thus a PI of 50% indicates that a patient on the experimental treatment is as likely to be better or worse as compared with a patient on the control treatment.\nThe PI is the metric associated with the Mann-Whitney-U test (aka Wilcoxon-Mann-Whitney). When modelled under a regression framework with conditioning on the covariate values of both subjects, we have a probabilistic index model (PIM).\nIn notational terms, if we let \\(y\\) denote a univariate outcome and \\(\\vec{x}\\) a vector of covariates for a unit, then the PI is given by \\(\\text{Pr}(y_i &lt; y_j | \\vec{x_i}, \\vec{x_j})\\) where \\(i\\) and \\(j\\) denote distinct units.\nTwo things are clear from this definition:\n\nThe PI does not provide information on the magnitude of the difference between two populations.\nThe measure is always comparing two different subjects, it does not give the probability that a single patient will benefit from a given treatment as compared with the conventional treatment.\n\nIn a two-sample setting we can use the MWU to compute the probabilistic index. However, when our treatment is continuous or we wish to condition on a set of covariates then it is desirable to embed the PI into a regression model. The approach is to model the conditional PI directly as a function of covariates:\n\\[\n\\begin{aligned}\n\\text{Pr}(Y_i &lt; Y_j | X_i, X_j) = m(X_i, X_j, \\beta)\n\\end{aligned}\n\\]\nwhere \\(m(.)\\) is some user-specified function and \\((Y_i, X_i)\\) are iid and \\(X_i\\), \\(X_j\\) and \\(\\beta\\) are vector quantities. It is convenient to choose \\(m\\) as:\n\\[\n\\begin{aligned}\nm(X_i, X_j, \\beta) = g^{-1}[(X_j - X_i)^\\top \\beta]\n\\end{aligned}\n\\]\nTo interpret the regression coefficient, consider two subjects \\(i\\) and \\(j\\) with covariate patterns \\(X^\\top = (Z_1, Z_2)\\) with \\(\\beta^\\top = (\\beta_1, \\beta_2)\\) (for a bivariate case). Say, subject \\(i\\) has covariate values \\((z_1, z_2)\\) and subject \\(j\\) has values \\((z_1 + 1, z_2)\\) so that both have the same value for \\(Z_2\\) but where \\(Z_1\\) differs by one unit. It follows that:\n\\[\n\\begin{aligned}\n\\text{Pr}(Y_i &lt; Y_j | Z_{1i} = z_1, Z_{1j} = z_1 + 1, Z_{2i} = Z_{2j}) = g^{-1}{\\beta_1}\n\\end{aligned}\n\\]\nso that \\(g^{-1}{\\beta_1}\\) gives the probability that a randomly selected subject with covariate value \\(z_1\\) for \\(Z_1\\) will have a lower outcome as compared with a randomly selected subject with a covariate value that is higher by one and where \\(Z_2\\) is the same for both subjects.\n\n\n\n\n\n\nNote\n\n\n\nNotice the absence of an intercept in these models. This means that when the covariate patterns are the same, the probability that \\(Y_i\\) is less than \\(Y_j\\) is 0.5 and vice versa.\n\n\nAs might be clear, the above can be handled via a logistic regression applied to the transformed binary outcome \\(I_{ij} = I(Y_i &lt; Y_j)\\) and predictors \\(X_{ij} = X_j - X_i\\). From this, the MLE give consistent estimates for \\(\\beta\\), [2]. However, despite the fact that \\((Y_i, X_i)\\) are mutually independent, the transformed data \\(I_{ij}\\) and \\(X_{ij}\\) are not. This is obviously the case if we consider \\(I_{ij} = I(Y_i &lt; Y_j)\\) and \\(I_{ik} = I(Y_i &lt; Y_k)\\) since both share \\(Y_i\\) making them no longer independent. Moreover, the \\(I_{ij}\\) have a correlation structure that is different from the typical block correlation structure in multi-level data. Thas introduced a sandwich estimator for the standard errors (frequentist setting) implemented in the R package pim, [2] and [3]. However, a bootstrap approach could also be used - simply take \\(B\\) bootstrap samples (with replacement) of size \\(n\\) and then repeat whatever estimation process was used.\n\n\n\n\n\n\nNote\n\n\n\nThe above specification can be modified to deal with ties by modifying the transformed outcome to \\(I(Y_i &lt; Y_j) + 0.5I(Y_i = Y_j)\\).\n\n\n\nReferences\n\n\n1. De Schryver M. A tutorial on probabilistic index models: Regression models for the effect size p(Y1 &gt; Y2). American Psychological Association. 2019;24.\n\n\n2. Thas O. Probabilistic index models. Journal of the Royal Statistical Society Series B Methodological. 2012;74:623–71.\n\n\n3. Meys J. Pim fit probabilistic index models. 2017."
  },
  {
    "objectID": "notebooks/robust-errors.html",
    "href": "notebooks/robust-errors.html",
    "title": "Robust errors for estimating proportion",
    "section": "",
    "text": "The goto approach for estimating an uncertainty interval for a proportion is to use the normal approximation of the binomial distribution:\n\\[\n\\begin{aligned}\n\\hat{p} \\pm z_{(1 - \\alpha)/2} \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{n}}\n\\end{aligned}\n\\]\nwhere \\(n\\) is the sample size, \\(\\hat{p}\\) is the observed sample proportion and \\(z\\) is the standard normal quantile (and typically set to \\(\\approx 2\\)).\nSay we had multiple estimates of the proportion, e.g. number of times we observe antimicrobial resistance out of the positive blood cultures we collected over the previous year. These estimates might come from differing hospitals and some might include repeat tests on individuals. This means that we have multiple levels of variation to deal with. One approach is to use a robust (sometimes call a Hubert White or sandwich) estimator for the standard errors.\nThis can be achieved by fitting a standard glm and then making an adjustment to the standard errors using the tools provided in the R sandwich package.\nSimulate data for 500 patients from 10 sites, some patients having repeat measures.\n\nlibrary(sandwich)\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(marginaleffects)\nlibrary(lme4)\n\nLoading required package: Matrix\n\n# library(gee)\nlibrary(\"geepack\")\n\n# N unique pts on which we have multiple obs, each pt nested within one of\n# the 10 sites\nN &lt;- 500\nN_site &lt;- 10\np_site &lt;- as.numeric(extraDistr::rdirichlet(1, rep(1, 10)))\nsites &lt;- sample(1:N_site, N, replace = T, prob = p_site)\nd_pt &lt;- data.table(\n  id_pt = 1:N,\n  site = sort(sites)\n)\n# number obs per pt - inflated here to make a point\nn_obs &lt;- rpois(N, 2)\nd &lt;- d_pt[unlist(lapply(1:N, function(x){\n  rep(x, n_obs[x])\n}))]\nd[, id_obs := 1:.N, keyby = id_pt]\n\n# about 60% (plogis(0.4)) resistant but with site and subject level\n# variability beyond the natural sampling variability due to varying \n# number of subjects per site\nnu &lt;- rnorm(N, 0, 0.5)\n# treat site as true fixed effect\nrho &lt;- rnorm(N_site, 0, 0.7)\nd[, eta := 0.4 + rho[site] + nu[id_pt]]\n\nd[, y := rbinom(.N, 1, plogis(eta))]\nd[, site := factor(site)]\nd[, id_pt := factor(id_pt)]\n\np_obs &lt;- d[, sum(y)/.N]\n\n# d[, .(y = sum(y), n = .N)]\n# distribution of frequency of observations on a pt\n# hist(d[, .N, keyby = id_pt][, N])\n\nThe raw numbers of observations at each site are shown in Figure 1.\n\nd_fig &lt;- copy(d)\nd_fig[y == 0, resp := \"Susceptible\"]\nd_fig[y == 1, resp := \"Resistant\"]\nggplot(d_fig, aes(x = site, fill = resp)) +\n  geom_bar() +\n  scale_fill_discrete(\"\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nFigure 1: Observations by site\n\n\n\n\n\nOverall, the observed proportion resistant to antibiotics is 0.62. Various ways exist to estimate the uncertainty.\nThe wald estimate for the uncertainty interval is calculated as:\n\n# wald (normal approximation)\nse_wald &lt;- sqrt(p_obs * (1-p_obs) / nrow(d))\np_0_lb &lt;- p_obs - qnorm(0.975) * se_wald\np_0_ub &lt;- p_obs + qnorm(0.975) * se_wald\n\nA GLM with only an intercept term will give the same prediction as the observed proportion and we can calculate the naive estimate of uncertainty as:\n\n# standard glm, not accounting for pt\nf1 &lt;- glm(y ~ 1, family = binomial, data = d)\n\npredict(f1, type = \"response\")[1]\n\n   1 \n0.62 \n\n# get naive standard errors\ns_f1 &lt;- summary(f1)$coef\n\n# model uncertainty naive\nlo_1 &lt;- qlogis(p_obs)\n# se from intercept term, i.e. we are just looking at the 'average' or\n# typical pt, over which we would expect heterogeneity\np_1_lb &lt;- plogis(lo_1 - qnorm(0.975) * s_f1[1, 2])\np_1_ub &lt;- plogis(lo_1 + qnorm(0.975) * s_f1[1, 2])\n\nWe can use the sandwich estimator to adjuste for heterogeneity as:\n\n# adjusted to account for heterogeneity due to site (we did not \n# adjust for site in the model) and repeat measure for pt\nsw_se &lt;- sqrt(vcovCL(f1, cluster = d[, .(site, id_pt)], type = \"HC1\")[1,1])\np_2_lb &lt;- plogis(lo_1 - qnorm(0.975) * sw_se)\np_2_ub &lt;- plogis(lo_1 + qnorm(0.975) * sw_se)\n\n\nf2 &lt;- glmer(y ~ (1|site) + (1|id_pt), data = d, family = binomial)\n\nNote that in the glmer model (with a non-linear link function) the predictions are first made on the link scale, averaged, and then back transformed. This means that the average prediction may not be exactly identical to the average of predictions.\nYou’ll note that the point estimate from the glmer deviates from the observed proportion. This can be for all of the following reasons:\n\nThe GLMM provides subject-specific estimates, conditional on the random effects.\nGLMMs involve shrinkage, where estimates for groups with less data are pulled towards the overall mean.\nLarger random effects can lead to bigger differences.\nThe GLMM estimate is a model-based estimate that accounts for the hierarchical structure of the data and provides a framework for inference.\n\nIn theory, a GEE could also be used but in R the GEE framework is not particularly well set up for multiple levels of clustering.\n\nsprintf(\"%.4f (%.4f, %.4f)\", p_obs, p_0_lb, p_0_ub)\n\n[1] \"0.6200 (0.5906, 0.6494)\"\n\n# Model based adjusting for site.\nsprintf(\"%.4f (%.4f, %.4f)\", p_obs, p_1_lb, p_1_ub)\n\n[1] \"0.6200 (0.5902, 0.6489)\"\n\n# Adjusted - account for heterogeneity due to site (we did not \n# adjust for site) and repeat measure for pt\nsprintf(\"%.4f (%.4f, %.4f)\", p_obs, p_2_lb, p_2_ub)\n\n[1] \"0.6200 (0.5093, 0.7195)\"\n\n# Finally a random effects model\navg_predictions(f2, re.form = NA, type = \"link\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)   S  2.5 % 97.5 %\n    0.608      0.271 2.24   0.0249 5.3 0.0767   1.14\n\nColumns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  link \n\navg_predictions(f2, re.form = NA, type = \"response\")\n\n\n Estimate Std. Error    z Pr(&gt;|z|)    S 2.5 % 97.5 %\n    0.647     0.0619 10.5   &lt;0.001 82.7 0.526  0.769\n\nColumns: estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n## Step 1\npred &lt;- predictions(f2, type = \"link\", re.form = NA)$estimate\n## Step 2: average\nplogis(mean(pred))\n\n[1] 0.647475\n\n\n\nReferences"
  },
  {
    "objectID": "notebooks/mann-whitney-u.html",
    "href": "notebooks/mann-whitney-u.html",
    "title": "Mann-Whitney U",
    "section": "",
    "text": "The MWU checks a rank sum difference between two independent groups and tests whether two groups have been drawn from the same population. It is an alternative to the t-test. But it only requires that the observations from both groups are at least ordinal such that you can discern for any two observations which one is greater (or better in some sense). In the classical interpretation, the test assumes that the distributions are identical under the null hypothesis and that they are not identical under the alternative distribution. Underlying the test is an interest in the probability that a randomly selected unit from one group fairs better than a randomly selected unit from the other. More concretely, the interest is int:\n\\[\n\\text{Pr}(X &gt; Y) \\ne \\text{Pr}(Y &gt; X)\n\\]\nand if this quantity exceeds \\(0.5\\) then, all things being equal, you would prefer assignment to the \\(X\\) group.\nOne approach to the procedure involves combining all the observations and ordering the records from best to worse (keeping track of which record belongs to which group). Each row is assigned a rank, the sum of the ranks is calculated for the first group (\\(T_1\\)) and the second group (\\(T_2\\)) and then the \\(U\\) statistics are computed as:\n\\[\n\\begin{aligned}\nU_1 &= n_1 n_2 + \\frac{n_1(n_1 + 1)}{2} - T_1 \\\\\nU_2 &= n_1 n_2 + \\frac{n_2(n_2 + 1)}{2} - T_2 \\\\\n\\end{aligned}\n\\]\nthe Mann-Whitney-U is given by \\(U = \\text{min}(U_1,U_2)\\), which is the test statistic.\nFor example, say we have units 1 to 20 in the first group and units 21 to 40 in the second with all the units in the first group having a better score than the units in the second.\n\nlibrary(data.table)\nlibrary(ggplot2)\n# contrived setup to make the scores for units ascend \n# (lower values considered better)\nd &lt;- data.table(\n  i = 1:40, score = sort(rnorm(40, 0, 1)), \n  group = rep(1:2, each = 20)\n)\nd[, rank := 1:40]\nn1 &lt;- d[group == 1, .N]\nn2 &lt;- d[group == 2, .N]\n\nNow add up the ranks for both groups.\n\n(T1 = d[group == 1, sum(rank)])\n\n[1] 210\n\n(T2 = d[group == 2, sum(rank)])\n\n[1] 610\n\n\nFrom these compute \\(U_1\\) and \\(U_2\\)\n\n(U_1 = n1*n2 + n1*(n1+1)/2 - T1)\n\n[1] 400\n\n(U_2 = n1*n2 + n2*(n2+1)/2 - T2)\n\n[1] 0\n\n\nThe above is equivalent to a pairwise comparison procedure (see later). From this, we can estimate the probability of superiority as referred to earlier (which I believe, but am not certain, is assuming that the two distributions differ only in location, not in shape) as:\n\n# here the contrived setup says that the value of x_1 and x_2 also equate to their ranks\n# and that lower values are better.\nx_1 &lt;- 1:20\nx_2 &lt;- 21:40\nn_1 &lt;- length(x_1)\nn_2 &lt;- length(x_2)\nu_1 &lt;- 0\nu_2 &lt;- 0\n\nk &lt;- 1\nfor(i in 1:length(x_1)){\n  for(j in 1:length(x_2)){\n    if(x_1[i] &lt; x_2[j]) u_1 &lt;- u_1 + 1\n    else if(x_1[i] &gt; x_2[j]) u_2 &lt;- u_2 + 1\n    k &lt;- k + 1\n  }\n}\nsprintf(\"u1 = %.0f, Pr(X&gt;Y) = %.2f, u2 = %.0f, Pr(Y&gt;X) = %.2f\", u_1, u_1/(n_1*n_2), u_2, u_2/(n_1*n_2))\n\n[1] \"u1 = 400, Pr(X&gt;Y) = 1.00, u2 = 0, Pr(Y&gt;X) = 0.00\"\n\n\nThat is, for all possible pairwise combinations, we compare the value in the first group to each value in second group and add up how often X &gt; Y and compute the probability estimate of \\(\\text(Pr)(X&gt;Y)\\) by simply dividing the number of occurrences by the total number of pairs.\nFor the test, we take the following reference points. First, under no difference, the expected value for \\(U\\) is\n\\[\n\\mathbb{E}[U] = \\frac{n_1 n_2}{2}\n\\]\nwith a standard standard error of:\n\\[\n\\sigma_U = \\sqrt{\\frac{n_1 n_2 (n_1 + n_2 + 1)}{12}}\n\\]\nUsing these, you can compute a z-value using a normal approximation (for large samples &gt; 20 per group) in the usual way by taking the observed value for \\(U\\) subtracting the expected value and dividing by the standard error:\n\\[\nz = \\frac{U - \\mu_u}{\\sigma_U}\n\\]\nand obtain a p-value for the test."
  },
  {
    "objectID": "notebooks/mann-whitney-u.html#footnotes",
    "href": "notebooks/mann-whitney-u.html#footnotes",
    "title": "Mann-Whitney U",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe intuition for the above is that \\(F_e(x)\\) gives the probability that \\(X_e\\) is greater than a specific value of \\(x\\), and \\(f_c(x) dx\\) gives the probability that \\(X_c\\) falls in a small interval around \\(x\\). The product of these terms gives the probability that \\(X_e &gt; X_c\\) for that small interval and thus integrating over all possible values of \\(x\\) gives the value we are after.↩︎"
  },
  {
    "objectID": "notebooks/random-walk-prior.html",
    "href": "notebooks/random-walk-prior.html",
    "title": "Random walk priors",
    "section": "",
    "text": "First order random walk\nFor regular spacings, a first-order random walk prior can be specified as:\n\\[\n\\begin{aligned}\n\\eta_0 &\\sim \\text{Logistic}(0,1) \\\\\n\\delta &\\sim \\text{Normal}(0, 1) \\\\\n\\sigma_\\delta &\\sim \\text{Exponential}(1) \\\\\n\\eta_{[1]} &= \\eta_0 \\\\\n\\eta_{[k]} &= \\sum_{i = 2}^{N}(\\eta_{[k-1]}  + \\delta  \\sigma_\\delta) \\\\\n\\end{aligned}\n\\]\nSimulate data from an oscillator:\n\nlibrary(data.table)\nlibrary(ggplot2)\n\nset.seed(2)\nd_obs &lt;- data.table(\n  x = sort(runif(100, 0, 2*pi))\n)\nd_obs[, eta := sin(x)]\nd_obs[, n := rpois(.N, 200)]\nd_obs[, y := rbinom(.N, n, plogis(eta))]\n\n# we only observe 30% of the data generated\nd_obs[, y_mis := rbinom(.N, 1, 0.7)]\n\nNaive implementation of a first order random walk in stan.\n\n\ndata {    \n  int N; \n  // the way the model is set up it does not matter if some of the n's are\n  // zero because the likelihood uses y_sub, which is obtained by reference\n  // to the missing indicator y_mis, which explicitly says that there were\n  // no observations at the given value of x.\n  array[N] int y;    \n  array[N] int n;    \n  vector[N] x;    \n  array[N] int y_mis; \n  \n  int prior_only;    \n  \n  // priors\n  real r_nu;\n  \n}    \ntransformed data {\n  // x_diff gives us the variable spacing in x and allows us to scale\n  // the variance appropriately\n  vector[N-1] x_diff;\n  // the number of observations we truly had once missingness is accounted for\n  int N_sub = N - sum(y_mis);\n  // our truly observed responses (successes) and trials\n  array[N_sub] int y_sub;\n  array[N_sub] int n_sub;\n  // \n  for(i in 1:(N-1)){x_diff[i] = x[i+1] - x[i];}\n  // go through the data that was passed in and build the data on which \n  // we will fit the model\n  int j = 1;\n  for(i in 1:N){\n    if(y_mis[i] == 0){\n      y_sub[j] = y[i];\n      n_sub[j] = n[i];\n      j += 1;\n    }\n  }  \n}\nparameters{  \n  // the first response\n  real b0;    \n  // offsets\n  vector[N-1] delta;    \n  // how variable the response is\n  real&lt;lower=0&gt; nu;   \n}    \ntransformed parameters{    \n  // the complete modelled mean response\n  vector[N] e; \n  // this is the variance scaled for the distance between each x\n  // note this is truly a variance and not an sd\n  vector[N-1] tau;    \n  // \n  vector[N_sub] eta_sub;    \n  // adjust the variance for the distance b/w doses    \n  // note that nu is squared to turn it into variance\n  for(i in 2:N){tau[i-1] = x_diff[i-1]*pow(nu, 2);}    \n  // resp is random walk with missingness filled in due to the \n  // dependency in the prior\n  e[1] = b0;    \n  // each subsequent observation has a mean equal to the previous one\n  // plus some normal deviation with mean zero and variance calibrated for\n  // the distance between subsequent observations.\n  for(i in 2:N){e[i] = e[i-1] + delta[i-1] * sqrt(tau[i-1]);}    \n  // eta_sub is what gets passed to the likelihood\n  { \n    int k = 1;\n    for(i in 1:N){\n      if(y_mis[i] == 0){\n        eta_sub[k] = e[i];\n        k += 1;\n      }\n    }\n  }\n}    \nmodel{    \n  // prior on initial response\n  target += logistic_lpdf(b0 | 0, 1);\n  // prior on sd\n  target += exponential_lpdf(nu | r_nu);\n  // standard normal prior on the offsets\n  target += normal_lpdf(delta | 0, 1);    \n  if(!prior_only){target += binomial_logit_lpmf(y_sub | n_sub, eta_sub);}    \n}    \ngenerated quantities{    \n  // predicted values at each value of x\n  vector[N] p;    \n  vector[N-1] e_diff;    \n  vector[N-1] e_grad;    \n  // compute diffs\n  for(i in 1:(N-1)){e_diff[i] = e[i+1] - e[i];}\n  e_grad = e_diff ./ x_diff;\n  p = inv_logit(e);\n}    \n\n\n\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/random-walk-01.stan\")\n\n\nld = list(\n  N = nrow(d_obs), \n  y = d_obs[, y], \n  n = d_obs[, n],\n  x = d_obs[, x], \n  y_mis = d_obs[, y_mis], \n  prior_only = F, \n  r_nu =  3\n  )\n\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 2000,\n  parallel_chains = 1, chains = 1, refresh = 0, show_exceptions = F,\n  max_treedepth = 10)\n\nRunning MCMC with 1 chain...\n\nChain 1 finished in 3.0 seconds.\n\n\nWarning: 2 of 2000 (0.0%) transitions ended with a divergence.\nSee https://mc-stan.org/misc/warnings for details.\n\nf1$summary(variables = c(\"nu\"))\n\n# A tibble: 1 × 10\n  variable  mean median    sd    mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 nu       0.533  0.519 0.103 0.0946 0.392 0.722  1.00    1221.    1114.\n\n\nRepresentation of output.\n\nd_out &lt;- data.table(f1$draws(variables = \"p\", format = \"matrix\"))\n\nd_fig &lt;- melt(d_out, measure.vars = names(d_out))\nd_fig &lt;- d_fig[, .(\n  mu = mean(value), \n  q_025 = quantile(value, prob = 0.025),\n  q_975 = quantile(value, prob = 0.975)\n), keyby = variable]\nd_fig[, ix := gsub(\"p[\", \"\", variable, fixed = T)]\nd_fig[, ix := as.numeric(gsub(\"]\", \"\", ix, fixed = T))]\nd_fig[, x := d_obs[ix, x]]\n\n\nggplot(d_obs, aes(x = x, y = plogis(eta))) +\n  geom_line(lty = 1) +\n  geom_point(data = d_obs[y_mis == 0],\n             aes(x = x, y = y/n), size = 0.7) +\n  geom_point(data = d_obs[y_mis == 1],\n             aes(x = x, y = y/n), size = 0.7, pch = 2) +\n  geom_ribbon(data = d_fig, \n              aes(x = x, ymin = q_025, ymax = q_975),\n              inherit.aes = F, fill = 2, alpha = 0.3) +\n  geom_line(data = d_fig, \n              aes(x = x, y = mu), col = 2) +\n  geom_point(data = d_fig, \n              aes(x = x, y = mu), col = 2, size = 0.6) +\n  scale_x_continuous(\"x\") +\n  scale_y_continuous(\"Probability\") +\n  theme_bw()\n\n\n\n\n\n\n\nFigure 1: True function (black line), data on which the model was fit (black points), data we did not see (black triangles), random walk (red line) with interpolated points (red) and uncertainty (red ribbon).\n\n\n\n\n\n\n\nSecond order random walk\nThe second order random walk for regular locations has density\n\\[\n\\begin{aligned}\n\\pi(x) \\propto \\exp\\left( -\\frac{1}{2} \\sum_{i=2}^{n-1} (x_{i-1} - 2x_i + x_{i+1})^2  \\right)\n\\end{aligned}\n\\]\nThe main term can be interpreted as an estimate of the second order derivative of a continuous time function. But this is not generally suitable for irregular spacings of x [1].\n\n\nReferences\n\n\n1. Lindgren F, Rue H. On the second-order random walk model for irregular locations. Scandinavian Journal of Statistics. 2008;35:691–700."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "maj-biostat.github.io",
    "section": "",
    "text": "Order By\n       Default\n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Title\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nReading Time\n\n\n\n\n\n\n\n\n\nFriday 4 Oct 2024\n\n\nMultinomial regression\n\n\n10 min\n\n\n\n\n\n\n\nThursday 3 Oct 2024\n\n\nLimitations of per-protocol analyses\n\n\n7 min\n\n\n\n\n\n\n\nWednesday 2 Oct 2024\n\n\nStrategies for handling Intercurrent Events - hypothetical strategy\n\n\n3 min\n\n\n\n\n\n\n\nMonday 30 Sep 2024\n\n\nProbabilistic Index Models\n\n\n4 min\n\n\n\n\n\n\n\nFriday 27 Sep 2024\n\n\nDesirability of Outcome Ranking (DOOR)\n\n\n12 min\n\n\n\n\n\n\n\nWednesday 25 Sep 2024\n\n\nUser-defined Probability Distributions in Stan\n\n\n2 min\n\n\n\n\n\n\n\nWednesday 25 Sep 2024\n\n\nMann-Whitney U\n\n\n14 min\n\n\n\n\n\n\n\nWednesday 25 Sep 2024\n\n\nRobust errors for estimating proportion\n\n\n4 min\n\n\n\n\n\n\n\nWednesday 18 Sep 2024\n\n\nRandom walk priors\n\n\n3 min\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Biostatistician working mostly in the area of Bayesian adaptive clinical trials using R and stan. The site contains various posts/reminders on topics that are relevant to my day-to-day work."
  },
  {
    "objectID": "about.html#repository-status",
    "href": "about.html#repository-status",
    "title": "About",
    "section": "Repository status",
    "text": "Repository status\n\nlibrary(git2r)\nrepo &lt;- git2r::repository(path = \".\")\nsummary(repo)\n\nLocal:    main /Users/mark/Documents/project/website/src/maj-biostat.github.io\nRemote:   main @ origin (https://github.com/maj-biostat/maj-biostat.github.io)\nHead:     [58b92d9] 2024-10-06: Add note on multilevel\n\nBranches:         1\nTags:             0\nCommits:         32\nContributors:     2\nStashes:          0\nIgnored files:    2\nUntracked files: 17\nUnstaged files:  39\nStaged files:     0\n\nLatest commits:\n[58b92d9] 2024-10-06: Add note on multilevel\n[b6c8d30] 2024-10-06: multinomial\n[23087c3] 2024-10-04: Update site\n[61c7f24] 2024-10-04: Add reference\n[85971cd] 2024-10-03: Update site"
  },
  {
    "objectID": "notebooks/door-1.html",
    "href": "notebooks/door-1.html",
    "title": "Desirability of Outcome Ranking (DOOR)",
    "section": "",
    "text": "DOOR analyses are claimed to be more patient centric. Instead of constructing summary measures by group for each outcome, the DOOR approach combines endpoints at a patient level and then creates a summary measure of the composite view for each intervention.\nThere are two approaches to a DOOR analysis, see [1]. The first approach uses the pairwise comparisons as introduced in Mann-Whitney-U. However, unlike the classical MWU, in the DOOR analysis, all the paired results are incorporated into the test statistic (this can also be done in MWU but wasn’t discussed in the earlier post). The other method used for the DOOR is a partial credit approach, but I do not really understand what that is about.\nAs a result, the DOOR analysis gives you an estimate of the probability that a randomly selected patient in the experimental group will have a better ranking than a randomly selected patient in the control group. The calculation used for the aggregated pairwise comparisons is:\n\\[\n\\begin{aligned}\n\\text{Pr}(door) = \\frac{ (n_{win} + 0.5 n_{tie}) } { n_e n_c }\n\\end{aligned}\n\\]\nwhere \\(n_{win}\\) is the number of times the units in the experimental group had better outcomes compared to the control group, \\(n_{tie}\\) is the number of ties, \\(n_e\\) is the number of units in the experimental group and \\(n_c\\) the number of units in the control group. This measure is also referred to as the probabilistic index [2] or probability of superiority, which will be cover in a separate post.\nIf there is no difference between the two arms, the probability will be close to 50%. Uncertainty intervals can be obtained via bootstrap or other means.\n\n\nLoading required package: Rcpp\n\n\nBuyseTest version 3.0.4\n\n\n\n\nTable 1: Ranking criteria for desirability of outcome for PJI\n\n\n\n\n\n\n\n\n\nRank\nAlive\nJoint Function\nTrt Success\nQoL\n\n\n\n\n1\nYes\nGood\nYes\nTiebreaker based on EQ5D5L\n\n\n2\nYes\nGood\nNo\nTiebreaker based on EQ5D5L\n\n\n3\nYes\nPoor1\nYes\nTiebreaker based on EQ5D5L\n\n\n4\nYes\nPoor\nNo\nTiebreaker based on EQ5D5L\n\n\n5\nNo\n-\n-\n-\n\n\n\n1\nGood joint function is based on thresholds related to patient reported success. A successful outcome at 12-months will be defined for knee PJI with an Oxford Knee Score (OKS) at 12 months of &gt;36 or an improvement (delta) from baseline of &gt;9 and for hip PJI as a Oxford Hip Score (OHS) of &gt;38 or an improvement of &gt;12 (35).\n\n\n\n\n\n\n\n\n\n\n\nConsider a DOOR schema and ranking specification for prosthetic joint infection as per Table 1. Patients are assessed and assigned ranks based on how they align with the schema with the goal of differentiating the overall or global outcome of a patient state.\nBelow 100 people per group are simulated based on some hypothetical pair of distributions for the schema. The door probability is computed along with its confidence interval (by bootstrapping):\n\nseed &lt;- 1\nset.seed(seed)\n\nn_e &lt;- 100\nn_c &lt;- 100\np_x_e &lt;- c(0.5, 0.3, 0.1, 0.1, 0.0)\np_x_c &lt;- c(0.3, 0.2, 0.2, 0.2, 0.1)\n  \nx_e &lt;- sample(1:5, n_e, replace = T, p_x_e)\nx_c &lt;- sample(1:5, n_c, replace = T, p_x_c)  \n\nn_win &lt;- 0\nn_tie &lt;- 0\nfor(i in 1:n_e){\n  for(j in 1:n_c){\n    if(x_e[i] &lt; x_c[j]) n_win &lt;- n_win + 1\n    if(x_e[i] == x_c[j]) n_tie &lt;- n_tie + 1\n  }\n}\n\n# estimate for door\npr_door &lt;- (n_win + 0.5 * n_tie)/(n_e*n_c)\n\nboot_door &lt;- function(ix_e, ix_c){\n  \n  x_e_new &lt;- x_e[ix_e]\n  x_c_new &lt;- x_c[ix_e]\n  \n  n_win &lt;- 0\n  n_tie &lt;- 0\n  for(i in 1:n_e){\n    for(j in 1:n_c){\n      if(x_e_new[i] &lt; x_c_new[j]) n_win &lt;- n_win + 1\n      if(x_e_new[i] == x_c_new[j]) n_tie &lt;- n_tie + 1\n    }\n  }\n  \n  (n_win + 0.5 * n_tie)/(n_e*n_c)\n}\n\nn_boot &lt;- 1000\npr_door_rep &lt;- numeric(n_boot)\nfor(i in 1:n_boot){\n  ix_e &lt;- sample(1:n_e, size = n_e, replace = T)\n  ix_c &lt;- sample(1:n_c, size = n_c, replace = T)\n  pr_door_rep[i] &lt;- boot_door(ix_e, ix_c)\n}\n# \ndoor_ci &lt;- quantile(pr_door_rep, probs = c(0.025, 0.975))\n\n# c(pr_door, door_ci)\n\nFrom above, the estimate for the door probability is 0.70 with a (bootstrapped) 95% CI of 0.63, 0.77.\nThe process is simple but the procedure itself does not readily admit to complex modelling. However, Follmann proposed using a logistic regression for the probability of superiority for each determinate pair of patients \\(i\\), \\(j\\) and covariate vectors \\(\\vec{z}_{ij} = \\vec{z}_i - \\vec{z}_j\\) such that the parameters in the model correspond to the log-odds that a patient with \\(\\vec{z}_i\\) has an outcome that is better than a patient with \\(\\vec{z}_j\\) [3]. The presentation from Follmann is pretty convoluted and I lost patience with it. The exposition of probabilistic index models by De Schryver, which is analogous, if not equivalent, is much clearer and will be discussed separately, Probabilistic Index Models.\nA shiny application for door analyses can be found at DOOR although it does not give any detail on the implementation of the methods used. Under the probability-based analysis tab, the overall door and then a decomposition based on each of the dichotomous door components is shown.\nScraping the source data of the site, you can at least recreate some of the statistics. For example, the door probabilities for the ARLG CRACKLE-I demo data as detailed in the door probability-based analysis tab, are replicated below for discharge from hospital:\n\n\n\n\nTable 2: Colistin data from shiny application for DOOR\n\n\n\n\n\n\n\n\n\ntrt\ndoor_num\ndoor_txt\nN\n\n\n\n\nCAZ-AVB\n1\nDischarged home\n6\n\n\nCAZ-AVB\n2\nAlive in hosp, discharged not to home, no renal failure\n17\n\n\nCAZ-AVB\n3\nAlive in hosp, discharged not to home, renal failure\n1\n\n\nCAZ-AVB\n4\nHospital death\n2\n\n\nColistin\n1\nDischarged home\n4\n\n\nColistin\n2\nAlive in hosp, discharged not to home, no renal failure\n25\n\n\nColistin\n3\nAlive in hosp, discharged not to home, renal failure\n5\n\n\nColistin\n4\nHospital death\n12\n\n\n\n\n\n\n\n\n\n\n\nn_e &lt;- d[trt == \"CAZ-AVB\", .N]\nn_c &lt;- d[trt == \"Colistin\", .N]\n\nn_win &lt;- 0\nn_tie &lt;- 0\nfor(i in 1:n_e){\n  for(j in 1:n_c){\n    if(d[trt == \"CAZ-AVB\"][i, discharge_num] &lt; \n       d[trt == \"Colistin\"][j, discharge_num]) n_win &lt;- n_win + 1\n    if(d[trt == \"CAZ-AVB\"][i, discharge_num] == \n       d[trt == \"Colistin\"][j, discharge_num]) n_tie &lt;- n_tie + 1\n  }\n}\npr_door_colistin &lt;- (n_win + 0.5 * n_tie)/(n_e*n_c)\n\n\nboot_door &lt;- function(ix_e, ix_c){\n  \n  x_e_new &lt;- d[trt == \"CAZ-AVB\"][ix_e, discharge_num]\n  x_c_new &lt;- d[trt == \"Colistin\"][ix_c, discharge_num]\n  \n  n_win &lt;- 0\n  n_tie &lt;- 0\n  for(i in 1:n_e){\n    for(j in 1:n_c){\n      if(x_e_new[i] &lt; x_c_new[j]) n_win &lt;- n_win + 1\n      if(x_e_new[i] == x_c_new[j]) n_tie &lt;- n_tie + 1\n    }\n  }\n  \n  (n_win + 0.5 * n_tie)/(n_e*n_c)\n}\n\nn_boot &lt;- 1e3\npr_door_rep &lt;- numeric(n_boot)\nfor(i in 1:n_boot){\n  ix_e &lt;- sample(1:n_e, size = n_e, replace = T)\n  ix_c &lt;- sample(1:n_c, size = n_c, replace = T)\n  pr_door_rep[i] &lt;- boot_door(ix_e, ix_c)\n}\npr_door_colistin_ci &lt;- quantile(pr_door_rep, probs = c(0.025, 0.975))\n\nGiving 0.57 and 95% CI of 0.49, 0.66.\nSimilarly, for renal failure:\n\nd[, .N, keyby = .(trt, renal_num, renal_txt)]\n\nKey: &lt;trt, renal_num, renal_txt&gt;\n        trt renal_num renal_txt     N\n     &lt;char&gt;     &lt;int&gt;    &lt;char&gt; &lt;int&gt;\n1:  CAZ-AVB         0        No    25\n2:  CAZ-AVB         1       Yes     1\n3: Colistin         0        No    39\n4: Colistin         1       Yes     7\n\nn_win &lt;- 0\nn_tie &lt;- 0\nfor(i in 1:n_e){\n  for(j in 1:n_c){\n    if(d[trt == \"CAZ-AVB\"][i, renal_num] &lt; \n       d[trt == \"Colistin\"][j, renal_num]) n_win &lt;- n_win + 1\n    if(d[trt == \"CAZ-AVB\"][i, renal_num] == \n       d[trt == \"Colistin\"][j, renal_num]) n_tie &lt;- n_tie + 1\n  }\n}\npr_door_colistin &lt;- (n_win + 0.5 * n_tie)/(n_e*n_c)\n\nwhich gives 0.56 aligning with the shiny app results.\n\nGeneralised pairwise comparisons\nGPC is a related method and frankly it seems a bit better thought out than DOOR, but I am not sure that it is as popular [4]. The outcomes of interest are first ranked in terms of importance and the pairwise comparison is run progressively on each outcome for all pairs. For the ties under each outcome, the procedure moves on to the outcome that has the next highest priority and so on.\nWhile GPC can be used to produce a range of summary measures, the original paper used net treatment benefit (NTB).\n\\[\n\\begin{aligned}\nNTB = \\frac{ (n_{win} - n_{loss}) } { n_{win} + n_{loss} + n_{tie} }\n\\end{aligned}\n\\]\nwhere \\(n_{win} + n_{loss} + n_{tie}\\) is typically equal to the total number of pairwise comparisons.\nUnlike the DOOR approach, GPC allows for component level contribution and event level correlation. In contrast to the Win Ratio, the net treatment benefit incorporates ties.\nAs an example, consider a situation where we have outcomes, as above, for death, joint function, treatment success and QoL. The procedure first runs pairwise comparisons for all units on death and the number of wins, draws and losses recorded, demonstration below.\n\nset.seed(seed)\nN &lt;- 100\nd &lt;- data.table(\n  id = 1:(2*N),\n  # expt is 1\n  trt = rep(1:0, each = N)\n)\nd[, death := rbinom(.N, 1, prob = 0.4 - 0.2 * trt)]\nd[, jf := rbinom(.N, 1, prob = 0.6 - 0 * trt)]\nd[, success := rbinom(.N, 1, prob = 0.65 + 0.15 * trt)]\nd[, qol := rnorm(.N, 0 + 0.4 * trt, 1)]\n\nn_e &lt;- d[trt == 1, .N]\nn_c &lt;- d[trt == 0, .N]\nn_win &lt;- numeric(4)\nn_loss &lt;- numeric(4)\nn_tie &lt;- numeric(4)\n\n# create a grid to compute all comparisons (quicker than looping)\nsetkey(d, id)\nd_all &lt;- CJ(i = 1:100, j = 100 + (1:100))\n# death\nd_all[, death_i := d[i, death]]\nd_all[, death_j := d[j, death]]\n# note sign direction differs dependent on context of comparison\nd_all[death_i &lt; death_j, death_res := 1]\nd_all[death_i &gt; death_j, death_res := -1]\nd_all[death_i == death_j, death_res := 0]\n# jf\nd_all[, jf_i := d[i, jf]]\nd_all[, jf_j := d[j, jf]]\nd_all[jf_i &gt; jf_j, jf_res := 1]\nd_all[jf_i &lt; jf_j, jf_res := -1]\nd_all[jf_i == jf_j, jf_res := 0]\n# success\nd_all[, success_i := d[i, success]]\nd_all[, success_j := d[j, success]]\nd_all[success_i &gt; success_j,  success_res := 1]\nd_all[success_i &lt; success_j,  success_res := -1]\nd_all[success_i == success_j, success_res := 0]\n# success\nd_all[, qol_i := d[i, qol]]\nd_all[, qol_j := d[j, qol]]\nd_all[qol_i &gt;  qol_j, qol_res := 1]\nd_all[qol_i &lt;  qol_j, qol_res := -1]\nd_all[qol_i == qol_j, qol_res := 0]\nhead(d_all)\n\nKey: &lt;i, j&gt;\n       i     j death_i death_j death_res  jf_i  jf_j jf_res success_i success_j\n   &lt;int&gt; &lt;num&gt;   &lt;int&gt;   &lt;int&gt;     &lt;num&gt; &lt;int&gt; &lt;int&gt;  &lt;num&gt;     &lt;int&gt;     &lt;int&gt;\n1:     1   101       0       1         1     1     0      1         1         1\n2:     1   102       0       0         0     1     1      0         1         0\n3:     1   103       0       0         0     1     1      0         1         0\n4:     1   104       0       1         1     1     1      0         1         0\n5:     1   105       0       1         1     1     1      0         1         1\n6:     1   106       0       0         0     1     0      1         1         0\n   success_res    qol_i      qol_j qol_res\n         &lt;num&gt;    &lt;num&gt;      &lt;num&gt;   &lt;num&gt;\n1:           0 1.293674  1.0744410       1\n2:           1 1.293674  1.8956548      -1\n3:           1 1.293674 -0.6029973       1\n4:           1 1.293674 -0.3908678       1\n5:           0 1.293674 -0.4162220       1\n6:           1 1.293674 -0.3756574       1\n\n\nGPC calculations:\n\n# ntb on death is as follows:\nntb &lt;- numeric(4)\nnames(ntb) &lt;- c(\"death\", \"jf\", \"success\", \"qol\")\nd_res &lt;- d_all[, .N, keyby = death_res]\nd_res[, pct := N / nrow(d_all)]\n\nntb[\"death\"] &lt;- (d_res[death_res == 1, N] - d_res[death_res == -1, N]) /  nrow(d_all)\n\n# for the ties on death, compute jf:\nd_res &lt;- d_all[death_res == 0, .N, keyby = jf_res]\nd_res[, pct := N / nrow(d_all)]\nntb[\"jf\"] &lt;- (d_res[jf_res == 1, N] - d_res[jf_res == -1, N]) /  nrow(d_all)\n\n# for comparisons on all pairs, don't condition:\n# d_res &lt;- d_all[, .N, keyby = jf_res]\n# d_res[, pct := N / nrow(d_all)]\n# d_res\n# (d_res[jf_res == 1, N] - d_res[jf_res == -1, N]) /  nrow(d_all)\n\n# for the ties on death and jf, compute success:\nd_res &lt;- d_all[death_res == 0 & jf_res == 0, .N, keyby = success_res]\nd_res[, pct := N / nrow(d_all)]\nntb[\"success\"] &lt;- (d_res[success_res == 1, N] - d_res[success_res == -1, N]) / nrow(d_all)\n\n# for the ties on death, jf and success, compute qol:\nd_res &lt;- d_all[death_res == 0 & jf_res == 0 & success_res == 0, .N, keyby = qol_res]\nd_res[, pct := N / nrow(d_all)]\nntb[\"qol\"] &lt;- (d_res[qol_res == 1, N] - d_res[qol_res == -1, N]) / nrow(d_all)\n\nNote that for all endpoints, we use the total number of pairwise comparisons as the denominator and not the number of ties left over from the previous outcome.\nThe resulting net treatment benefit reported on each outcome:\n\nntb\n\n  death      jf success     qol \n 0.2300  0.0527  0.0574  0.0455 \n\n\nTaking the cumulative sum, progresses from the effect of each component through to an overall effect:\n\ncumsum(ntb)\n\n  death      jf success     qol \n 0.2300  0.2827  0.3401  0.3856 \n\n\nThe NTB is absolute measure ranging from -1 to 1 with zero being no effect. It estimates the probability that a random unit on the expt arm will do better than a random unit on the control arm minus the probability that a random unit on the control arm will do better than a random unit on the expt arm. For example, if \\(Pr(E&gt;C) = 0.7\\), then \\(Pr(E&lt;C) = 0.3\\) and \\(NTB = 0.7 - 0.3 = 0.4\\).\nYou can compute the overall effect directly with the following:\n\nn_win &lt;- d_all[death_res == 1, .N] + d_all[death_res == 0 & jf_res == 1, .N] +\n   + d_all[death_res == 0 & jf_res == 0 & success_res == 1, .N] +\n   + d_all[death_res == 0 & jf_res == 0 & success_res == 0 & qol_res == 1, .N]\n\nn_loss &lt;- d_all[death_res == -1, .N] + d_all[death_res == 0 & jf_res == -1, .N] +\n   + d_all[death_res == 0 & jf_res == 0 & success_res == -1, .N] +\n   + d_all[death_res == 0 & jf_res == 0 & success_res == 0 & qol_res == -1, .N]\n\n# n_ties &lt;- d_all[death_res == 0 & jf_res == 0 & success_res == 0, .N] \n\n(n_win - n_loss) / nrow(d_all)\n\n[1] 0.3856\n\n\nThe NTB is known to be the inverse of the number needed to treat, i.e. 1/ number of pt you need to trt to avoid one bad outcome. For large samples, inference can again be conducted via bootstrap. R provides the BuyseTest package that allows for stratification (beyond the implicit treatment level stratification).\n\nff1 &lt;- trt ~ bin(death, operator = \"&lt;0\") + bin(jf) + bin(success) + cont(qol)\nf1 &lt;- BuyseTest(ff1, data = d, trace = 0)\ns_f1 &lt;- summary(f1)\n\n       Generalized pairwise comparisons with 4 prioritized endpoints\n\n - statistic       : net treatment benefit  (delta: endpoint specific, Delta: global) \n - null hypothesis : Delta == 0 \n - confidence level: 0.95 \n - inference       : H-projection of order 1 after atanh transformation \n - treatment groups: 1 (treatment) vs. 0 (control) \n - neutral pairs   : re-analyzed using lower priority endpoints\n - results\n endpoint total(%) favorable(%) unfavorable(%) neutral(%) uninf(%)  delta\n    death   100.00        33.20          10.20      56.60        0 0.2300\n       jf    56.60        15.30          10.03      31.27        0 0.0527\n  success    31.27         9.86           4.12      17.29        0 0.0574\n      qol    17.29        10.92           6.37       0.00        0 0.0455\n  Delta CI [2.5% ; 97.5%]    p.value    \n 0.2300    [0.106;0.3469] 0.00032703 ***\n 0.2827   [0.1355;0.4177] 0.00022230 ***\n 0.3401   [0.1882;0.4761] 2.2250e-05 ***\n 0.3856     [0.2326;0.52] 2.6463e-06 ***\n\n\nIn the results, the totals, wins, loss and ties are presented as percentages rather than counts. For example, the total column effectively represents the proportion of pairs that carry over from one outcome to the next; for death there were 5660 pairs that carried over to joint function there were 3127 pairs that carried over to the treatment success outcome and so on. These can be visualised as:\n\nd_fig &lt;- data.table(s_f1)\nd_fig &lt;- d_fig[, 1:5]\nnames(d_fig) &lt;- c(\n  \"endpoint\", \"total\", \"wins\", \"losses\", \"tie\"\n)\nd_fig &lt;- melt(d_fig, id.vars = \"endpoint\")\nd_fig &lt;- d_fig[variable != \"total\"]\n\nggplot(d_fig, aes(x = endpoint, y = value, fill = variable)) +\n  geom_bar(stat='identity') +\n  scale_fill_discrete(\"\") +\n  scale_y_continuous(\"Percentage\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\nFigure 1: Contribution by each endpoint\n\n\n\n\n\nInference can be conducted on all pairs for all outcomes by indicating that the hierarchical perspective is not required:\n\nf2 &lt;- BuyseTest(ff1, hierarchical = FALSE, data = d, trace = 0)\nsummary(f2)\n\n       Generalized pairwise comparisons with 4 endpoints\n\n - statistic       : net treatment benefit  (delta: endpoint specific, Delta: global) \n - null hypothesis : Delta == 0 \n - confidence level: 0.95 \n - inference       : H-projection of order 1 after atanh transformation \n - treatment groups: 1 (treatment) vs. 0 (control) \n - results\n endpoint weight total(%) favorable(%) unfavorable(%) neutral(%) uninf(%)\n    death   0.25      100        33.20          10.20      56.60        0\n       jf   0.25      100        26.64          17.64      55.72        0\n  success   0.25      100        30.80          13.80      55.40        0\n      qol   0.25      100        64.02          35.98       0.00        0\n  delta  Delta CI [2.5% ; 97.5%]    p.value    \n 0.2300 0.0575   [0.0272;0.0877] 0.00020121 ***\n 0.0900 0.0800    [0.037;0.1227] 0.00026848 ***\n 0.1700 0.1225   [0.0699;0.1744] 5.4724e-06 ***\n 0.2804 0.1926    [0.1296;0.254] 3.3839e-09 ***\n\n\n\n\nReferences\n\n\n1. Chamberlain J. Desirability of outcome ranking for status epilepticus. Research Methods in Neurology. 2023;101.\n\n\n2. De Schryver M. A tutorial on probabilistic index models: Regression models for the effect size p(Y1 &gt; Y2). American Psychological Association. 2019;24.\n\n\n3. Follmann D. Regression analysis based on pairwise ordering of patients’ clinical histories. Statistics in Medicine. 2002;21.\n\n\n4. Buyse M. Generalized pairwise comparisons of prioritized outcomes in the two-sample problem. Statistics in Medicine. 2010;29."
  },
  {
    "objectID": "notebooks/multinomial-regression.html",
    "href": "notebooks/multinomial-regression.html",
    "title": "Multinomial regression",
    "section": "",
    "text": "The multinomial distribution is a generalisation of the binomial distribution, [1]. The binomial counts the successes in a fixed number of trials each classed as success or failure. The multinomial distribution keeps track of trials whose outcomes have multiple categories, e.g. agree, neutral, disagree.\nWe have \\(N\\) objects, each is independently placed into one of \\(K\\) categories. An object is placed in category \\(k\\) with probability \\(p_k\\) where \\(\\sum_{k=1}^K p_k = 1\\) and \\(p_k \\ge 0\\) for all \\(k\\). If we let \\(Y_1\\) be the count of category 1 objects, \\(Y_2\\) be the count for category 2 etc so that \\(Y_1 + \\dots + Y_K = N\\) then \\(\\mathbf{Y} = (Y_1, \\dots, Y_K)\\) is said to have a multinomial distribution with parameters \\(N\\) and \\(\\mathbf{p} = (p_1, \\dots, p_K)\\). This can be written as \\(\\mathbf{Y} \\sim \\text{Mult}_K(N, \\mathbf{p})\\) where the \\(\\mathbf{Y}\\) is referred to as a random vector as it is a vector of random variables.\nIf \\(\\mathbf{Y} \\sim \\text{Mult}_K(N, \\mathbf{p})\\) then the joint PMF is:\n\\[\n\\begin{aligned}\n\\text{Pr}(Y_1 = y_1, \\dots, Y_K = y_K) &= \\frac{N!}{y_1!y_2!\\dots y_K!} p_1^{y_1}p_2^{y_2}\\dots  p_K^{y_K} \\\\\n&= \\begin{pmatrix}\nN \\\\\ny_1, \\dots, y_K\n\\end{pmatrix} \\prod_{k=1}^K p_k^{y_k}\n\\end{aligned}\n\\]\nThe marginal distribution of a multinomial are all binomial with \\(Y_k \\sim Bin(N, p_k)\\).\nLumping categories together will form multinomial distribution with the revised \\(K^\\prime\\) representing the new (smaller) set of categories and both counts and probabilities for the lumped groups being additive."
  },
  {
    "objectID": "notebooks/multinomial-regression.html#setup",
    "href": "notebooks/multinomial-regression.html#setup",
    "title": "Multinomial regression",
    "section": "Setup",
    "text": "Setup\nAssume that for a city, it is well known that the dominant modes of travel (to work) are walk/bike, public transport and car with a distribution provided in Table 1. Note that these are mutually exclusive and exhaustive of the possible modes of transport. Now say we want to investigate ways to move people away from cars. Interventions may span from city wide information on the benefits of using public transport, to financial discounts to restrictions on parking or taxes. Assume we want to evaluate whether an information mail-out versus financial discounts on public transport achieves greater transition to public transport.\n\n\n\n\nTable 1: Distribution of dominant mode of transport used to get to work\n\n\n\n\n\n\n\n\n\n\n\n\n\nMode of transport\nProportion\n\n\n\n\nWalk/bike\n0.07\n\n\nPublic transport\n0.33\n\n\nCar\n0.60\n\n\n\n\n\n\n\n\n\n\n\nget_data &lt;- function(\n    N = 250,\n    p0 = c(0.07, 0.33, 0.6),\n    p1 = c(0.10, 0.50, 0.4)){\n  \n  d &lt;- data.table(id = 1:N)\n  d[, trt := rep(0:1, each = N/2)]\n  \n  d[trt == 0, y := sample(seq_along(p0), .N, replace = T, prob = p0)]\n  d[trt == 1, y := sample(seq_along(p1), .N, replace = T, prob = p1)]\n  \n  d\n}\n\nWe take a random sample of adult working residents from the city. The sample is randomised 1:1 to a monthly email lasting for 3-months that details the benefit of using public transport versus a 3-month discount for the all public transport networks within the city. At 3-months, the sample cohort are surveyed to determine their dominant mode of transport in the last month."
  },
  {
    "objectID": "notebooks/multinomial-regression.html#contingency-table",
    "href": "notebooks/multinomial-regression.html#contingency-table",
    "title": "Multinomial regression",
    "section": "Contingency table",
    "text": "Contingency table\nOne approach to the analysis is via a contingency table posing the research hypothesis Do dominant modes of transport differ under the two interventions? The Chi-squared test of independence is run on the observed counts of each cell as follows:\n\\[\n\\begin{aligned}\nX^2 &= \\sum_{i=1}^r \\sum_{j=1}^c \\frac{(O_{ij} - e_{ij})^2}{e_{ij}}\n\\end{aligned}\n\\]\nwhere the expected counts are based on the row and column totals (i.e. assuming independence across groups):\n\\[\n\\begin{aligned}\ne_{ij} = \\frac{O_{i.} O_{.j}}{O_{..}}\n\\end{aligned}\n\\]\nwhere \\(O_{i.}\\) denotes the row totals, \\(O_{.j}\\) the column totals and \\(O_{..}\\) denotes the grand total.\nIf the null hypothesis is true then the observed and the expected frequencies will be similar to one another and \\(\\chi^2\\) will be small. If \\(\\chi^2\\) is too large then the null would be rejected suggesting that the treatment and dominant modes of travel are not independent. Specifically, we would reject the null if the test statistic was found to be greater than or equal to a \\(\\chi^2\\) distribution that has \\((r-1)(c-1)\\) degrees of freedom, i.e. reject null if \\(X^2 \\ge \\chi^2_{(r-1)(c-1);\\alpha}\\) where \\(\\alpha\\) is the significance level.\nA sketch of the approach is shown below.\n\nset.seed(1)\nd &lt;- get_data()\n\n# observed\nm_obs &lt;- as.matrix(dcast(d[, .N, keyby = .(trt, y)],\n                      trt ~ y, value.var = \"N\"))\n\ntot_cols &lt;- colSums(m_obs[, 2:4])\ntot_rows &lt;- rowSums(m_obs[, 2:4])\n\n# expected\nm_e &lt;- rbind(\n  tot_cols  * tot_rows[1] / sum(tot_rows),\n  tot_cols  * tot_rows[2] / sum(tot_rows)\n)\n\n# chisqured statistic vs critical value\n\nv_stats &lt;- c(\n  chisq_obs = sum(  ((m_obs[, -1] - m_e)^2)/m_e ) ,\n  chisq_crit = qchisq(0.95, 2 * 1)\n)\n\nround(c(\n  v_stats, \n  p_value = pchisq(v_stats[1], 2 * 1, lower.tail = F)), 3)\n\n        chisq_obs        chisq_crit p_value.chisq_obs \n            6.053             5.991             0.048 \n\n\nSince the observed test statistic is greater than the critical value, we would reject the null in this case. The above can be automatically with the built-in function:\n\nres &lt;- chisq.test(m_obs[, -1])\nres\n\n\n    Pearson's Chi-squared test\n\ndata:  m_obs[, -1]\nX-squared = 6.0528, df = 2, p-value = 0.04849"
  },
  {
    "objectID": "notebooks/multinomial-regression.html#multi-logit-regression",
    "href": "notebooks/multinomial-regression.html#multi-logit-regression",
    "title": "Multinomial regression",
    "section": "Multi-logit regression",
    "text": "Multi-logit regression\nTo implement the multi-logit regression a long format is usually adopted so that we have each unit \\(i\\) has an outcome \\(Y_i\\) equal to one of the possible categories.\nA simple sum-to-zero implementation is shown below.\n\n\ndata {\n  // Each unit has an outcome corresponding to one of K categories\n  int K;\n  // Number of units\n  int N;\n  // Number of terms in linear predictor (all lp have the \n  // same terms here). Includes intercept.\n  int D;\n  // Outcome variable (one of the categories)\n  array[N] int y;\n  // design matrix\n  matrix[N, D] x;\n}\nparameters {\n  vector[K-1] a_raw;\n  vector[K-1] b_raw;\n}\ntransformed parameters {\n  //            k1  k2  k3 etc\n  // intercept  -   -   -\n  //         x  -   -   -\n  matrix[D, K] b;\n  \n  b[1, ] = append_row(a_raw, -sum(a_raw))';\n  b[2, ] = append_row(b_raw, -sum(b_raw))';\n}\nmodel {\n  matrix[N, K] x_beta = x * b;\n\n  to_vector(a_raw) ~ normal(0, 5);\n  to_vector(b_raw) ~ normal(0, 5);\n\n  for (n in 1:N) {\n    y[n] ~ categorical_logit(x_beta[n]');\n  }\n}\ngenerated quantities{\n  \n  matrix[K, 2] p;\n  \n  vector[K] l0 = to_vector(b[1, ]);\n  vector[K] l1 = to_vector(b[1, ] + b[2, ]);\n  \n  p[, 1] = softmax(l0);\n  p[, 2] = softmax(l1);\n  \n}\n\n\nAnd a fixed pivot implementation is\n\n\ndata {\n  // Each unit has an outcome corresponding to one of K categories\n  int K;\n  // Number of units\n  int N;\n  // Number of terms in linear predictor (all lp have the \n  // same terms here). Includes intercept.\n  int D;\n  // Outcome variable (one of the categories)\n  array[N] int y;\n  // design matrix\n  matrix[N, D] x;\n}\nparameters {\n  //            k1  k2  k3 etc\n  // intercept  -   -   -\n  //         x  -   -   -\n  matrix[D, K-1] b_raw;\n}\ntransformed parameters {\n  //            k1  k2  k3 etc\n  // intercept  -   -   -\n  //         x  -   -   -\n  matrix[D, K] b;\n  \n  b[, 1:(K-1)] = b_raw;\n  b[, K] = rep_vector(0.0, D);\n}\nmodel {\n  matrix[N, K] x_beta = x * b;\n\n  to_vector(b_raw) ~ normal(0, 5);\n\n  for (n in 1:N) {\n    y[n] ~ categorical_logit(x_beta[n]');\n  }\n}\ngenerated quantities{\n  \n  matrix[K, 2] p;\n  \n  vector[K] l0 = to_vector(b[1, ]);\n  vector[K] l1 = to_vector(b[1, ] + b[2, ]);\n  \n  p[, 1] = softmax(l0);\n  p[, 2] = softmax(l1);\n  \n}\n\n\nFit both models to the data\n\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/multi-logit-01.stan\")\nm2 &lt;- cmdstanr::cmdstan_model(\"stan/multi-logit-02.stan\")\n\nld &lt;- list(\n  N = nrow(d),\n  K = length(unique(d$y)),\n  y = d$y,\n  D = 2,\n  x = cbind(1, d$trt)\n)\n\nf1 &lt;- m1$sample(data = ld, chains = 1, iter_sampling = 1000, refresh = 0)\nf2 &lt;- m2$sample(data = ld, chains = 1, iter_sampling = 1000, refresh = 0)\n\nRunning MCMC with 1 chain...\n\nChain 1 finished in 0.9 seconds.\nRunning MCMC with 1 chain...\n\nChain 1 finished in 0.6 seconds.\n\n\nBoth approaches faithfully recover the empirical proportions for the two treatment groups as shown in Table 2. The pivot model gives the most direct path to interpreting the model parameters. However, note that the models are structurally different and cannot be considered completely equivalent since different prior weights enter the models.\n\n\n\n\nTable 2: Observed and modeled distribution for mode of transport\n\n\n\n\n\n\n\n\n\ntrt\ny\nN\ntot\np\nmu_f1\nmu_f2\n\n\n\n\n0\n1\n7\n125\n0.056\n0.057\n0.056\n\n\n0\n2\n46\n125\n0.368\n0.366\n0.370\n\n\n0\n3\n72\n125\n0.576\n0.577\n0.574\n\n\n1\n1\n12\n125\n0.096\n0.097\n0.096\n\n\n1\n2\n60\n125\n0.480\n0.479\n0.479\n\n\n1\n3\n53\n125\n0.424\n0.424\n0.426\n\n\n\n\n\n\n\n\n\n\nThe parameter estimates from the linear predictors from the two models are summarised below. The terms (treatment effects) of interest are those associated with the second model f2, specifically, b[2,1] and b[2,2]. These suggesting that (1) units in the treatment group are more likely to have walking/bike than car as their dominant mode of transport and (2) units in the treatment group are more likely to have public transport than car as their dominant mode of transport.\n\nf1$summary(variables = \"b\")\n\n# A tibble: 6 × 10\n  variable    mean median    sd   mad     q5    q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 b[1,1]   -1.43   -1.43  0.271 0.258 -1.88  -0.994 1.00      201.     327.\n2 b[2,1]    0.382   0.391 0.339 0.345 -0.165  0.925 1.00      195.     366.\n3 b[1,2]    0.488   0.483 0.162 0.158  0.227  0.759 1.00      198.     232.\n4 b[2,2]    0.0985  0.102 0.213 0.208 -0.237  0.432 1.01      230.     367.\n5 b[1,3]    0.946   0.941 0.163 0.156  0.683  1.21  0.999     416.     625.\n6 b[2,3]   -0.481  -0.481 0.214 0.216 -0.830 -0.123 1.00      388.     375.\n\nf2$summary(variables = \"b\")\n\n# A tibble: 6 × 10\n  variable   mean median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 b[1,1]   -2.40  -2.38  0.419 0.423 -3.17   -1.76    1.00     353.     491.\n2 b[2,1]    0.875  0.868 0.538 0.549  0.0177  1.76    1.01     369.     376.\n3 b[1,2]   -0.443 -0.445 0.196 0.181 -0.769  -0.0980  1.00     491.     608.\n4 b[2,2]    0.562  0.555 0.275 0.277  0.112   1.02    1.00     506.     600.\n5 b[1,3]    0      0     0     0      0       0      NA         NA       NA \n6 b[2,3]    0      0     0     0      0       0      NA         NA       NA \n\n\nThese results are consistent with the results from the contingency table analysis in that they suggest the public transport discount intervention may increase the likelihood of people taking this form of transport to work.\nUnlike the contingency analysis, the the multi-logit approach offers the usual regression benefit of being able to adjust for covariates that may be relevant."
  },
  {
    "objectID": "notebooks/multinomial-regression.html#poisson-regression",
    "href": "notebooks/multinomial-regression.html#poisson-regression",
    "title": "Multinomial regression",
    "section": "Poisson regression",
    "text": "Poisson regression\nMultinomial logit models can also be fit using an equivalent log-linear model and a series of Poisson likelihoods. This is mathematically equivalent to the multinomial and computationally the Poisson approach can be easier, see McElreath2020 p365.\nAn implementation is shown below\n\n\ndata {\n  // Each unit has an outcome corresponding to one of K categories\n  int K;\n  // Number of units\n  int N;\n  // Outcome variable (one of the categories)\n  // y1= walk/bike, y2=public transport, y3=car\n  array[N] int y1;\n  array[N] int y2;\n  array[N] int y3;\n  // design matrix\n  vector[N] x;\n}\nparameters {\n  vector[K] a;\n  vector[K] b;\n}\nmodel {\n\n  to_vector(a) ~ normal(0, 5);\n  to_vector(b) ~ normal(0, 5);\n  \n  target += poisson_log_lpmf(y1 | a[1] + x * b[1]);\n  target += poisson_log_lpmf(y2 | a[2] + x * b[2]);\n  target += poisson_log_lpmf(y3 | a[3] + x * b[3]);\n  \n}\ngenerated quantities{\n  \n  matrix[K, 2] p;\n  \n  p[1, 1] = exp(a[1]) * inv( exp(a[1]) + exp(a[2]) + exp(a[3]));\n  p[2, 1] = exp(a[2]) * inv( exp(a[1]) + exp(a[2]) + exp(a[3]));\n  p[3, 1] = exp(a[3]) * inv( exp(a[1]) + exp(a[2]) + exp(a[3]));\n  \n  p[1, 2] = exp(a[1] + b[1]) * inv( exp(a[1] + b[1]) + exp(a[2] + b[2]) + exp(a[3] + b[3]));\n  p[2, 2] = exp(a[2] + b[2]) * inv( exp(a[1] + b[1]) + exp(a[2] + b[2]) + exp(a[3] + b[3]));\n  p[3, 2] = exp(a[3] + b[3]) * inv( exp(a[1] + b[1]) + exp(a[2] + b[2]) + exp(a[3] + b[3]));\n\n}\n\n\nIn order to fit the model, it is necessary to first create an indicator variable for the occurrence of each category.\n\n# need to create a binary indicator for each category:\nd[, y1 := ifelse(y == 1, 1, 0)]\nd[, y2 := ifelse(y == 2, 1, 0)]\nd[, y3 := ifelse(y == 3, 1, 0)]\n\nm3 &lt;- cmdstanr::cmdstan_model(\"stan/poisson-01.stan\")\n\nld &lt;- list(\n  N = nrow(d),\n  K = length(unique(d$y)),\n  y1 = d$y1, \n  y2 = d$y2,\n  y3 = d$y3,\n  x = d$trt\n)\n\nf3 &lt;- m3$sample(data = ld, chains = 1, iter_sampling = 1000, refresh = 0)\n\nRunning MCMC with 1 chain...\n\nChain 1 finished in 0.4 seconds.\n\nf3$summary(variables = \"b\")\n\n# A tibble: 3 × 10\n  variable   mean median    sd   mad      q5     q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;     &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 b[1]      0.528  0.532 0.482 0.445 -0.280   1.36   1.00      630.     485.\n2 b[2]      0.258  0.257 0.196 0.200 -0.0624  0.586  1.00      640.     662.\n3 b[3]     -0.309 -0.302 0.180 0.173 -0.608  -0.0170 0.999     683.     607.\n\n\nThe combined set of results are shown below, again the empirical proportions for each group are captured by the poisson implementation of the model.\n\n\n\n\nTable 3: Observed and modeled distribution for mode of transport (multi-logit and poisson)\n\n\n\n\n\n\n\n\n\ntrt\ny\nN\ntot\np\nmu_f1\nmu_f2\nmu_f3\n\n\n\n\n0\n1\n7\n125\n0.056\n0.057\n0.056\n0.057\n\n\n0\n2\n46\n125\n0.368\n0.366\n0.370\n0.370\n\n\n0\n3\n72\n125\n0.576\n0.577\n0.574\n0.573\n\n\n1\n1\n12\n125\n0.096\n0.097\n0.096\n0.095\n\n\n1\n2\n60\n125\n0.480\n0.479\n0.479\n0.480\n\n\n1\n3\n53\n125\n0.424\n0.424\n0.426\n0.424"
  },
  {
    "objectID": "notebooks/multinomial-regression.html#extensions",
    "href": "notebooks/multinomial-regression.html#extensions",
    "title": "Multinomial regression",
    "section": "Extensions",
    "text": "Extensions\nOne of the natural extensions of multinomial regression is the use of cluster level effects that are correlated across categories. For more detail, see [4]."
  },
  {
    "objectID": "notebooks/multinomial-regression.html#footnotes",
    "href": "notebooks/multinomial-regression.html#footnotes",
    "title": "Multinomial regression",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that if we have three categories and assign category 3 as the reference then even though our logits are in terms of \\(\\log(p_1/p_3)\\) and \\(\\log(p_2/p_3)\\), we can still compute a logit for \\(\\log(p_1/p_2)\\) by subtracting the logit for \\(\\log(p_2/p_3)\\) from that for \\(\\log(p_1/p_3)\\).↩︎"
  },
  {
    "objectID": "notebooks/limits-of-per-protocol.html",
    "href": "notebooks/limits-of-per-protocol.html",
    "title": "Limitations of per-protocol analyses",
    "section": "",
    "text": "Patients in RCTs that discontinue before the endpoint often have poorer prognosis than those who continue treatment. Additionally, discontinuation is more common in the treatments that create more side effects or have less clear benefit.\nThe traditional per-protocol analyses will exclude those patients that are not completers and that deviate in some unacceptable way from the protocol (e.g. early discontinuation of treatment) and then run the primary analysis unchanged. That is, the comparison groups are defined in part by post randomisation events that are influenced by treatment group status and other factors. This can be problematic in that it violates the randomisation principle, the treatment groups can become unbalanced in either known or unknown covariates, selection bias can arise, effect estimates may be biased and external validity threatened, [Greenland2008?]. The following example illustrates this.\nCompare a new antihypertensive (A) to a standard treatment (B) for lowering blood pressure in patients with existing hypertension in an RCT. At 6-months patients are assessed to be either still hypertensive (0) or no longer hypertensive (1). One thousands patients are randomised, 500 to each arm.\nIt is common for trials to show differential adherence by study group. Here, assume that A causes more side effects than B and at 3 months, 20% of patients stop taking A due to side effects and 4% stop taking B for a side effect intercurrent event. We interpret this as a protocol deviation (although who knows whether this would actually be consider to be a protocol deviation in reality). Additionally, assume that the patients who experience side effects (and therefore would dropout of the traditional PP analysis) tend to have more severe hypertension and would have shown less improvement in blood pressure status irrespective of the treatment they received.\nThe traditional per-protocol analysis excludes those that deviate from the protocol and we would therefore have around 400 patients in A and 480 patients in B.\nFinally assume that the true percentage that are no longer hypertensive at 6 months is 40% and 20% in group A and B respectively.\nBelow is a simulation of the assumed data generation process.\n\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(parallel)\n\nget_data &lt;- function(\n    N = 1000\n){\n  \n  d &lt;- data.table(i = 1:N)\n  d[, trt := rep(0:1, each = N/2)]\n  d[, sev := rnorm(N, 0, 1) ]\n  \n  d[trt == 0, p_ae := plogis(qlogis(0.04) + 0.4 * sev)]\n  d[trt == 1, p_ae := plogis(qlogis(0.40) + 0.4 * sev)]\n  \n  d[, discont := rbinom(.N, 1, p_ae)]\n  \n  d[trt == 0, p_y := plogis(qlogis(0.20) - 0.3 * sev)]\n  d[trt == 1, p_y := plogis(qlogis(0.40) - 0.3 * sev)]\n  \n  d[, y := rbinom(.N, 1, p_y)]\n  \n  d\n}\n\nSimulating this data generation process a large number of times, the ITT estimate along with the PP estimates can be computed to gain some insight of their long-run properties.\n\nm_res &lt;- do.call(rbind, mclapply(1:1e4, FUN = function(i){\n  d &lt;- get_data()\n\n  # ITT analysis\n  f1 &lt;- glm(y ~ trt, data = d, family = binomial())\n  rd_f1 &lt;- diff(predict(f1, type = \"response\", newdata = data.table(trt = 0:1)))\n  \n  # Traditional PP analysis \n  f2 &lt;- glm(y ~ trt, data = d[discont == 0], family = binomial()) \n  rd_f2 &lt;- diff(predict(f2, type = \"response\", newdata = data.table(trt = 0:1)))\n  \n  # G-comp - weights per the full sample\n  f3 &lt;- glm(y ~ trt + sev, data = d[discont == 0], family = binomial()) \n  \n  d_trt_1 &lt;- copy(d)\n  d_trt_1[, trt := 1]\n  d_trt_0 &lt;- copy(d)\n  d_trt_0[, trt := 0]\n  \n  f3_eta_trt_1 &lt;- predict(f3, newdata = d_trt_1)\n  f3_eta_trt_0 &lt;- predict(f3, newdata = d_trt_0)\n  \n  rd_f3 &lt;- plogis(mean(f3_eta_trt_1))  - plogis(mean(f3_eta_trt_0))\n  \n  c(rd_f1, rd_f2, rd_f3)\n  \n}, mc.cores = 6))\n\nFigure 1 shows the results. Specifically, the distribution of the estimated treatment effect (risk difference) which is known to have a true value of 0.2 in favour of the new drug (A).\nUnder the ITT analysis (where we ignore the fact that the ICE occurred and simply proceed to analyse all the data, irrespective of whether the ICE occurred or not) the long-run expected value for the MLE estimate of the treatment effect aligns with the true value of 0.2.\nHowever, in the traditional PP analysis, we drop those patients for whom the protocol deviation applies. We fit the same model as was used in the ITT analysis to the remaining data. For this approach, we can see that the expected value for the MLE estimate is inflated.\nThe final plot shows the results from a revised approach to the per-protocol analysis where we:\n\nrun the analysis assuming that the deviations are censored, i.e. we drop anyone that had the side effects\nadd variables that are predictive of the ICE into the model\nfor the entire data set make predictions of the outcome assuming that all patients are assigned to the standard treatment (A)\nrepeat 3 for the patients assuming that all patients are assigned to the standard treatment (B)\ncompute the treatment effect (risk difference) as the difference between the means of the predicted values each transformed back to the risk scale\n\nThis final approach is aligned with a G-computation perspective and gives results similar to those that would be produced from an inverse probability of censoring weighting scheme. In both cases, we are effectively, producing a re-weighted estimate of the effect, but going about it in slightly different ways.\nUnder this revised per-protocol approach, we once again produce an estimate of the treatment effect that has a expected value close to the known true value of 0.2. Clearly, this is a very much simplified and synthetic example, but it is only intended to give an introduction.\n\nd_fig &lt;- data.table(m_res)\nnames(d_fig) &lt;- c(\"itt\", \"pp_1\", \"pp_2\")\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\n\nd_fig[variable == \"itt\", variable := \"ITT\"]\nd_fig[variable == \"pp_1\", variable := \"Traditional PP\"]\nd_fig[variable == \"pp_2\", variable := \"PP via G-Computation\"]\nd_fig[, variable := factor(variable, levels = c(\n  \"ITT\", \"Traditional PP\", \"PP via G-Computation\"\n))]\n\nggplot(d_fig, aes(x = value, group = variable, col = variable)) + \n  geom_density() +\n  geom_vline(data = d_fig[, mean(value), keyby = variable], \n             aes(xintercept = V1, col = variable)) +\n  scale_color_discrete(\"Analysis\") +\n  theme_bw() +\n  theme(legend.position = \"bottom\") +\n  facet_wrap(~variable, ncol  = 1)\n\n\n\n\n\n\n\nFigure 1: Distribution of effect estimates under ITT, traditional per-protocol and g-computation under the present of ICE\n\n\n\n\n\nThe difference between the two per-protocol approaches can be emphasised by looking at the distribution of the percentage differences between the ITT effect and the PP effects as shown in Figure 2. For the traditional approach, the treatment effect is, on average, about 5% higher than it should be whereas under the revised approach, the PP approach aligns fairly well with the ITT estimate (with both being aligned with the true value).\n\nd_fig &lt;- data.table(m_res)\nnames(d_fig) &lt;- c(\"itt\", \"pp_1\", \"pp_2\")\nd_fig[, pct_diff_1 := 100 * (pp_1 - itt)/itt]\nd_fig[, pct_diff_2 := 100 * (pp_2 - itt)/itt]\n\nd_fig &lt;- d_fig[, .(pct_diff_1, pct_diff_2)]\nd_fig &lt;- melt(d_fig, measure.vars = names(d_fig))\n\nd_fig[variable == \"pct_diff_1\", variable := \"% change (traditional PP vs ITT)\"]\nd_fig[variable == \"pct_diff_2\", variable := \"% change (g-computation PP vs ITT)\"]\n\nd_fig[, variable := factor(variable, levels = c(\n  \"% change (traditional PP vs ITT)\", \n  \"% change (g-computation PP vs ITT)\"\n))]\n\n\nggplot(d_fig, aes(x = value, group = variable, col = variable)) + \n  geom_density() +\n  geom_vline(data = d_fig[, mean(value), keyby = variable], \n             aes(xintercept = V1, col = variable)) +\n  scale_color_discrete(\"Approach\") +\n  scale_x_continuous(breaks = seq(-40, 40, by = 10)) +\n  theme_bw() +\n  theme(legend.position = \"bottom\") +\n  facet_wrap(~variable, ncol = 1)\n\n\n\n\n\n\n\nFigure 2: Distribution of percentage change from the ITT estimate - traditional per-protocol and g-computation"
  },
  {
    "objectID": "notebooks/custom-distribution-stan.html",
    "href": "notebooks/custom-distribution-stan.html",
    "title": "User-defined Probability Distributions in Stan",
    "section": "",
    "text": "Overview\nSome of this material can be found in the stan user guide and this is solely to serve as a reference in my own words.\nTo implement, you just need to provide a function to increment the total log-probability appropriately.\n\n\n\n\n\n\nNote\n\n\n\nWhen a function with the name ending in *_lpdf* or *_lpmf* is defined, the stan compiler automatically makes a *_lupdf* or lupmf version. Only normalised custom distributions are permitted.\n\n\nAssume that we want to create a custom distribution per:\n\\[\n\\begin{aligned}\nf(x) &= (1-a) x^{-a}\n\\end{aligned}\n\\]\ndefined for \\(a \\in [0,1]\\) and \\(x \\in [0,1]\\) with cdf:\n\\[\n\\begin{aligned}\nF_x &= x^{a-1}\n\\end{aligned}\n\\]\nWe can generate draws from this distribution using the inverse cdf method:\n\nlibrary(data.table)\nlibrary(ggplot2)\nlibrary(cmdstanr)\n\nThis is cmdstanr version 0.8.1\n\n\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n\n\n- CmdStan path: /Users/mark/.cmdstan/cmdstan-2.35.0\n\n\n- CmdStan version: 2.35.0\n\nf_x &lt;- function(x, a){\n  if(a &lt; 0 | a &gt; 1) stop(\"only defined for a in [0,1]\")\n  if(any(x &lt; 0 | x &gt; 1)) stop(\"only defined for x in [0,1]\")\n  (1-a) * x ^ -a\n}\nF_x &lt;- function(x, a){\n  if(a &lt; 0 | a &gt; 1) stop(\"only defined for a in [0,1]\")\n  if(any(x &lt; 0 | x &gt; 1)) stop(\"only defined for x in [0,1]\")\n  x^(1-a)\n}\nF_inv_x &lt;- function(u, a){\n  if(a &lt; 0 | a &gt; 1) stop(\"only defined for a in [0,1]\")\n  if(any(u &lt; 0 | u &gt; 1)) stop(\"only defined for x in [0,1]\")\n  u ^ (1 / (1-a))\n}\n\na &lt;- 0.35\nx &lt;- seq(0, 1, len = 1000)\nd_fig &lt;- data.table(x = x, y = f_x(x, a))\nd_sim &lt;- data.table(\n  y_sim = F_inv_x(runif(1e6), a)\n)\n\nggplot(d_fig, aes(x = x, y = y)) +\n  geom_histogram(data = d_sim, aes(x = y_sim, y = ..density..),\n               inherit.aes = F, fill = 1, alpha = 0.2,\n               binwidth = density(d_sim$y_sim)$bw) + \n  geom_line() +\n  theme_bw()\n\nWarning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(density)` instead.\n\n\n\n\n\n\n\n\n\n\n\nfunctions {\n  real custom_lpdf(vector x, real alpha) {\n    \n    int n_x = num_elements(x);\n    vector[n_x] lpdf;\n    for(i in 1:n_x){\n      \n      lpdf[i] = log1m(alpha) - alpha * log(x[i]);\n    }  \n    return sum(lpdf);\n  }\n}\ndata {\n  int N;\n  vector[N] y;\n}\n\nparameters {\n  real&lt;lower=0, upper = 1&gt; a;\n}\nmodel {\n  target += exponential_lpdf(a | 1);\n  target += custom_lpdf(y | a);   \n}\n\n\n\nm1 &lt;- cmdstanr::cmdstan_model(\"stan/custom-dist-1.stan\")\n\nld = list(\n  N = 1000, \n  y = d_sim$y_sim[1:1000]\n)\n\n\nf1 &lt;- m1$sample(\n  ld, iter_warmup = 1000, iter_sampling = 1000,\n  parallel_chains = 1, chains = 1, refresh = 0, show_exceptions = F,\n  max_treedepth = 10)\n\nRunning MCMC with 1 chain...\n\nChain 1 finished in 0.2 seconds.\n\nf1$summary(variables = c(\"a\"))\n\n# A tibble: 1 × 10\n  variable  mean median     sd    mad    q5   q95  rhat ess_bulk ess_tail\n  &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 a        0.351  0.350 0.0205 0.0218 0.317 0.383  1.01     330.     374.\n\npost &lt;- data.table(f1$draws(variables = \"a\", format = \"matrix\"))\nhist(post$a)\n\n\n\n\n\n\n\n\n\n\nReferences"
  }
]